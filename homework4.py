import requests
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import time
import warnings
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import seaborn as sns
from collections import Counter
import random
import re
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

class DLTSpider:
    def __init__(self):
        self.base_url = "https://www.zhcw.com/kjxx/dlt/"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        
    def get_page_data(self):
        """è·å–æŒ‡å®šé¡µé¢çš„æ•°æ®"""
        try:
            print("å°è¯•ä»ç½‘ç»œè·å–æ•°æ®...")
            # å¦‚æœç½‘ç»œä¸å¯ç”¨ï¼Œç›´æ¥ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
            with open("wangye.html", "r", encoding='utf-8') as f:
                return [f.read()]
        except FileNotFoundError:
            print("æœ¬åœ°HTMLæ–‡ä»¶ä¸å­˜åœ¨")
            return None

    def parse_lottery_data(self, html_content_list):
        """è§£æå¼€å¥–æ•°æ®"""
        all_data = []

        # å¦‚æœä¼ å…¥çš„æ˜¯å•ä¸ªHTMLå†…å®¹ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
        if isinstance(html_content_list, str):
            html_content_list = [html_content_list]

        for page_num, html_content in enumerate(html_content_list, 1):
            print(f"æ­£åœ¨è§£æç¬¬ {page_num} é¡µæ•°æ®...")

            soup = BeautifulSoup(html_content, 'html.parser')

            # æŸ¥æ‰¾åŒ…å«å¼€å¥–æ•°æ®çš„è¡¨æ ¼
            table = soup.find('table')

            if not table:
                print(f"ç¬¬ {page_num} é¡µæœªæ‰¾åˆ°æ•°æ®è¡¨æ ¼")
                continue

            # æŸ¥æ‰¾è¡¨æ ¼çš„tbodyéƒ¨åˆ†
            tbody = table.find('tbody')
            if not tbody:
                print(f"ç¬¬ {page_num} é¡µæœªæ‰¾åˆ°è¡¨æ ¼æ•°æ®")
                continue

            # è§£ææ¯ä¸€è¡Œæ•°æ®
            rows = tbody.find_all('tr')

            for row in rows:
                try:
                    cells = row.find_all('td')
                    if len(cells) < 14:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„åˆ—
                        continue

                    # æå–æœŸå·
                    period = cells[0].get_text(strip=True)

                    # æå–å¼€å¥–æ—¥æœŸ
                    date_text = cells[1].get_text(strip=True)
                    # æå–æ—¥æœŸéƒ¨åˆ†ï¼Œå»æ‰æ˜ŸæœŸä¿¡æ¯
                    date_match = date_text.split('ï¼ˆ')[0] if 'ï¼ˆ' in date_text else date_text

                    # æå–å‰åŒºå·ç 
                    front_numbers = []
                    front_spans = cells[2].find_all('span', class_='jqh')
                    for span in front_spans:
                        front_numbers.append(span.get_text(strip=True))

                    # æå–ååŒºå·ç 
                    back_numbers = []
                    back_spans = cells[3].find_all('span', class_='jql')
                    for span in back_spans:
                        back_numbers.append(span.get_text(strip=True))

                    # æå–é”€å”®é¢
                    sales_amount = cells[4].get_text(strip=True)

                    # æå–ä¸€ç­‰å¥–ä¿¡æ¯
                    first_prize_count = cells[5].get_text(strip=True)
                    first_prize_amount = cells[6].get_text(strip=True)
                    first_prize_plus_count = cells[7].get_text(strip=True)
                    first_prize_plus_amount = cells[8].get_text(strip=True)

                    # æå–äºŒç­‰å¥–ä¿¡æ¯
                    second_prize_count = cells[9].get_text(strip=True)
                    second_prize_amount = cells[10].get_text(strip=True)
                    second_prize_plus_count = cells[11].get_text(strip=True)
                    second_prize_plus_amount = cells[12].get_text(strip=True)

                    # æå–å¥–æ± é‡‘é¢
                    prize_pool = cells[13].get_text(strip=True)

                    # ç»„è£…æ•°æ®
                    lottery_data = {
                        'æœŸå·': period,
                        'å¼€å¥–æ—¥æœŸ': date_match,
                        'å‰åŒºå·ç ': ' '.join(front_numbers),
                        'ååŒºå·ç ': ' '.join(back_numbers),
                        'é”€å”®é¢': sales_amount,
                        'ä¸€ç­‰å¥–æ³¨æ•°': first_prize_count,
                        'ä¸€ç­‰å¥–å•æ³¨å¥–é‡‘': first_prize_amount,
                        'ä¸€ç­‰å¥–è¿½åŠ æ³¨æ•°': first_prize_plus_count,
                        'ä¸€ç­‰å¥–è¿½åŠ å•æ³¨å¥–é‡‘': first_prize_plus_amount,
                        'äºŒç­‰å¥–æ³¨æ•°': second_prize_count,
                        'äºŒç­‰å¥–å•æ³¨å¥–é‡‘': second_prize_amount,
                        'äºŒç­‰å¥–è¿½åŠ æ³¨æ•°': second_prize_plus_count,
                        'äºŒç­‰å¥–è¿½åŠ å•æ³¨å¥–é‡‘': second_prize_plus_amount,
                        'å¥–æ± é‡‘é¢': prize_pool
                    }

                    all_data.append(lottery_data)

                except Exception as e:
                    print(f"è§£æè¡Œæ•°æ®æ—¶å‡ºé”™: {e}")
                    continue

            print(f"ç¬¬ {page_num} é¡µè§£æå®Œæˆï¼Œè·å¾— {len(rows)} æ¡æ•°æ®")

        # æŒ‰æœŸå·æ’åºï¼Œç¡®ä¿æ•°æ®é¡ºåºæ­£ç¡®
        if all_data:
            all_data.sort(key=lambda x: int(x['æœŸå·']), reverse=True)

        return all_data

    def crawl_lottery_data(self, target_periods=100):
        """çˆ¬å–æŒ‡å®šæœŸæ•°çš„å¼€å¥–æ•°æ®"""
        print("å¼€å§‹è·å–å¤§ä¹é€å¼€å¥–æ•°æ®...")

        # è·å–HTMLå†…å®¹
        html_content_list = self.get_page_data()

        if not html_content_list:
            print("æœªèƒ½è·å–åˆ°æ•°æ®")
            return []

        # è§£ææ‰€æœ‰é¡µé¢çš„æ•°æ®
        all_data = self.parse_lottery_data(html_content_list)

        if not all_data:
            print("æœªèƒ½è§£æåˆ°å¼€å¥–æ•°æ®")
            return []

        print(f"æ€»å…±è§£æåˆ° {len(all_data)} æ¡å¼€å¥–æ•°æ®")

        # è¿‡æ»¤2025å¹´7æœˆ1æ—¥ä¹‹å‰çš„æ•°æ®
        cutoff_date = datetime(2025, 7, 1)
        filtered_data = []

        for data in all_data:
            try:
                # è§£ææ—¥æœŸ
                date_obj = datetime.strptime(data['å¼€å¥–æ—¥æœŸ'], '%Y-%m-%d')
                if date_obj < cutoff_date:
                    filtered_data.append(data)
            except Exception as e:
                print(f"æ—¥æœŸè§£æé”™è¯¯: {data['å¼€å¥–æ—¥æœŸ']} - {e}")
                continue

        print(f"è¿‡æ»¤åè·å¾— {len(filtered_data)} æ¡2025å¹´7æœˆ1æ—¥ä¹‹å‰çš„æ•°æ®")

        # å¦‚æœéœ€è¦é™åˆ¶æœŸæ•°ï¼Œå–æœ€æ–°çš„target_periodsæœŸ
        if len(filtered_data) > target_periods:
            filtered_data = filtered_data[:target_periods]
            print(f"æŒ‰éœ€æ±‚é™åˆ¶ä¸ºæœ€æ–° {target_periods} æœŸæ•°æ®")

        return filtered_data

class DLTAnalyzer:
    def __init__(self, data):
        self.df = pd.DataFrame(data)
        self.prepare_data()
    
    def prepare_data(self):
        """æ•°æ®é¢„å¤„ç†"""
        if self.df.empty:
            print("æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
            return
        
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        self.df['å¼€å¥–æ—¥æœŸ'] = pd.to_datetime(self.df['å¼€å¥–æ—¥æœŸ'], errors='coerce')
        
        # æ¸…ç†é”€å”®é¢æ•°æ®
        self.df['é”€å”®é¢'] = self.df['é”€å”®é¢'].astype(str).str.replace(',', '').str.replace('å…ƒ', '')
        self.df['é”€å”®é¢'] = pd.to_numeric(self.df['é”€å”®é¢'], errors='coerce').fillna(0)
        
        # æŒ‰æ—¥æœŸæ’åº
        self.df = self.df.sort_values('å¼€å¥–æ—¥æœŸ').reset_index(drop=True)
        
        # è¿‡æ»¤æ‰2025å¹´7æœˆ1æ—¥ä¹‹åçš„æ•°æ®
        cutoff_date = datetime(2025, 7, 1)
        self.df = self.df[self.df['å¼€å¥–æ—¥æœŸ'] < cutoff_date]
        
        # æ·»åŠ æ˜ŸæœŸå‡ åˆ—
        self.df['æ˜ŸæœŸå‡ '] = self.df['å¼€å¥–æ—¥æœŸ'].dt.day_name()
        self.df['ä¸­æ–‡æ˜ŸæœŸ'] = self.df['å¼€å¥–æ—¥æœŸ'].dt.dayofweek.map({
            0: 'å‘¨ä¸€', 1: 'å‘¨äºŒ', 2: 'å‘¨ä¸‰', 3: 'å‘¨å››', 4: 'å‘¨äº”', 5: 'å‘¨å…­', 6: 'å‘¨æ—¥'
        })

        print(f"æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œå…±{len(self.df)}æ¡æœ‰æ•ˆæ•°æ®")
        print(f"æ—¥æœŸèŒƒå›´ï¼š{self.df['å¼€å¥–æ—¥æœŸ'].min()} åˆ° {self.df['å¼€å¥–æ—¥æœŸ'].max()}")
    
    def analyze_sales_trend(self):
        """åˆ†æé”€å”®é¢å˜åŒ–è¶‹åŠ¿å¹¶é¢„æµ‹"""
        if self.df.empty or self.df['é”€å”®é¢'].sum() == 0:
            print("é”€å”®é¢æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œè¶‹åŠ¿åˆ†æ")
            return
        
        # åˆ›å»ºå›¾è¡¨
        plt.figure(figsize=(15, 10))
        
        # å­å›¾1ï¼šé”€å”®é¢æ—¶é—´åºåˆ—
        plt.subplot(2, 2, 1)
        plt.plot(self.df['å¼€å¥–æ—¥æœŸ'], self.df['é”€å”®é¢'], marker='o', markersize=3, linewidth=1)
        plt.title('å¤§ä¹é€é”€å”®é¢å˜åŒ–è¶‹åŠ¿')
        plt.xlabel('å¼€å¥–æ—¥æœŸ')
        plt.ylabel('é”€å”®é¢ï¼ˆå…ƒï¼‰')
        plt.xticks(rotation=45)
        plt.grid(True, alpha=0.3)
        
        # å­å›¾2ï¼šé”€å”®é¢åˆ†å¸ƒç›´æ–¹å›¾
        plt.subplot(2, 2, 2)
        plt.hist(self.df['é”€å”®é¢'], bins=20, alpha=0.7, edgecolor='black')
        plt.title('é”€å”®é¢åˆ†å¸ƒ')
        plt.xlabel('é”€å”®é¢ï¼ˆå…ƒï¼‰')
        plt.ylabel('é¢‘æ¬¡')
        plt.grid(True, alpha=0.3)
        
        # å­å›¾3ï¼šç§»åŠ¨å¹³å‡çº¿
        plt.subplot(2, 2, 3)
        window = min(10, len(self.df) // 4)
        if window >= 2:
            moving_avg = self.df['é”€å”®é¢'].rolling(window=window).mean()
            plt.plot(self.df['å¼€å¥–æ—¥æœŸ'], self.df['é”€å”®é¢'], alpha=0.5, label='åŸå§‹æ•°æ®')
            plt.plot(self.df['å¼€å¥–æ—¥æœŸ'], moving_avg, color='red', linewidth=2, label=f'{window}æœŸç§»åŠ¨å¹³å‡')
            plt.title('é”€å”®é¢ç§»åŠ¨å¹³å‡çº¿')
            plt.xlabel('å¼€å¥–æ—¥æœŸ')
            plt.ylabel('é”€å”®é¢ï¼ˆå…ƒï¼‰')
            plt.legend()
            plt.xticks(rotation=45)
            plt.grid(True, alpha=0.3)
        
        # å­å›¾4ï¼šé¢„æµ‹ç»“æœ
        plt.subplot(2, 2, 4)
        recent_data = self.df['é”€å”®é¢'].tail(10)
        predicted_sales = recent_data.mean()

        plt.plot(range(len(recent_data)), recent_data, 'b-o', markersize=5, label='æœ€è¿‘10æœŸé”€å”®é¢')
        plt.axhline(y=predicted_sales, color='red', linestyle='--', label=f'é¢„æµ‹é”€å”®é¢: {predicted_sales:.0f}å…ƒ')
        plt.title('é”€å”®é¢é¢„æµ‹')
        plt.xlabel('æœŸæ•°')
        plt.ylabel('é”€å”®é¢ï¼ˆå…ƒï¼‰')
        plt.legend()
        plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.show()
        
        # æ‰“å°è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        print("\n=== é”€å”®é¢ç»Ÿè®¡åˆ†æ ===")
        print(f"æ•°æ®æœŸé—´ï¼š{self.df['å¼€å¥–æ—¥æœŸ'].min().strftime('%Y-%m-%d')} è‡³ {self.df['å¼€å¥–æ—¥æœŸ'].max().strftime('%Y-%m-%d')}")
        print(f"æ€»æœŸæ•°ï¼š{len(self.df)}æœŸ")
        print(f"å¹³å‡é”€å”®é¢ï¼š{self.df['é”€å”®é¢'].mean():.2f}å…ƒ")
        print(f"é”€å”®é¢ä¸­ä½æ•°ï¼š{self.df['é”€å”®é¢'].median():.2f}å…ƒ")
        print(f"æœ€é«˜é”€å”®é¢ï¼š{self.df['é”€å”®é¢'].max():.2f}å…ƒ")
        print(f"æœ€ä½é”€å”®é¢ï¼š{self.df['é”€å”®é¢'].min():.2f}å…ƒ")
        print(f"æ ‡å‡†å·®ï¼š{self.df['é”€å”®é¢'].std():.2f}å…ƒ")
        print(f"\né¢„æµ‹2025å¹´7æœˆ1æ—¥åæœ€è¿‘ä¸€æœŸé”€å”®é¢ï¼š{predicted_sales:.0f}å…ƒ")

        return predicted_sales

    def analyze_number_frequency(self, top_n=10):
        """åˆ†æå·ç å‡ºç°é¢‘ç‡"""
        if self.df.empty:
            print("æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œå·ç é¢‘ç‡åˆ†æ")
            return

        # æå–æ‰€æœ‰å‰åŒºå’ŒååŒºå·ç 
        all_front_numbers = []
        all_back_numbers = []

        for _, row in self.df.iterrows():
            front_numbers = row['å‰åŒºå·ç '].split()
            back_numbers = row['ååŒºå·ç '].split()

            all_front_numbers.extend([int(num) for num in front_numbers])
            all_back_numbers.extend([int(num) for num in back_numbers])

        # è®¡ç®—å·ç é¢‘ç‡
        front_number_freq = Counter(all_front_numbers)
        back_number_freq = Counter(all_back_numbers)

        # åˆ›å»ºå®Œæ•´çš„å‰åŒºå’ŒååŒºå·ç é¢‘ç‡ç»Ÿè®¡
        front_freq_complete = {i: front_number_freq.get(i, 0) for i in range(1, 36)}
        back_freq_complete = {i: back_number_freq.get(i, 0) for i in range(1, 13)}

        # åˆ›å»ºå¯è§†åŒ–
        plt.figure(figsize=(20, 12))

        # å‰åŒºå·ç é¢‘ç‡çƒ­åŠ›å›¾
        plt.subplot(2, 2, 1)
        front_matrix = np.array(list(front_freq_complete.values())).reshape(7, 5)
        front_labels = np.array(list(front_freq_complete.keys())).reshape(7, 5)

        sns.heatmap(front_matrix, annot=front_labels, fmt='d', cmap='YlOrRd',
                   cbar_kws={'label': 'å‡ºç°æ¬¡æ•°'})
        plt.title('å‰åŒºå·ç å‡ºç°é¢‘ç‡çƒ­åŠ›å›¾ï¼ˆ1-35ï¼‰')

        # ååŒºå·ç é¢‘ç‡çƒ­åŠ›å›¾
        plt.subplot(2, 2, 2)
        back_matrix = np.array(list(back_freq_complete.values())).reshape(3, 4)
        back_labels = np.array(list(back_freq_complete.keys())).reshape(3, 4)

        sns.heatmap(back_matrix, annot=back_labels, fmt='d', cmap='YlOrRd',
                   cbar_kws={'label': 'å‡ºç°æ¬¡æ•°'})
        plt.title('ååŒºå·ç å‡ºç°é¢‘ç‡çƒ­åŠ›å›¾ï¼ˆ1-12ï¼‰')

        # å‰åŒºTopå·ç æŸ±çŠ¶å›¾
        plt.subplot(2, 2, 3)
        common_front = front_number_freq.most_common(top_n)
        front_numbers, front_counts = zip(*common_front)
        plt.bar([str(num) for num in front_numbers], front_counts, color='skyblue')
        plt.title(f'å‰åŒºå·ç å‡ºç°é¢‘ç‡Top {top_n}')
        plt.xlabel('å·ç ')
        plt.ylabel('å‡ºç°æ¬¡æ•°')
        plt.grid(axis='y', alpha=0.3)

        # ååŒºTopå·ç æŸ±çŠ¶å›¾
        plt.subplot(2, 2, 4)
        common_back = back_number_freq.most_common(top_n)
        back_numbers, back_counts = zip(*common_back)
        plt.bar([str(num) for num in back_numbers], back_counts, color='lightcoral')
        plt.title(f'ååŒºå·ç å‡ºç°é¢‘ç‡Top {top_n}')
        plt.xlabel('å·ç ')
        plt.ylabel('å‡ºç°æ¬¡æ•°')
        plt.grid(axis='y', alpha=0.3)

        plt.tight_layout()
        plt.show()

        # åˆ†æçƒ­å·å’Œå†·å·
        print(f"\n=== å·ç å‡ºç°é¢‘ç‡åˆ†æ ===")
        print(f"åˆ†ææœŸæ•°ï¼š{len(self.df)}æœŸ")

        # å‰åŒºçƒ­å·å’Œå†·å·
        front_hot_numbers = [num for num, _ in front_number_freq.most_common(10)]
        front_cold_numbers = [num for num in range(1, 36) if front_number_freq.get(num, 0) <= 2]

        print(f"\nå‰åŒºçƒ­å·ï¼ˆTop 10ï¼‰ï¼š{', '.join(map(str, front_hot_numbers))}")
        print(f"å‰åŒºå†·å·ï¼ˆå‡ºç°â‰¤2æ¬¡ï¼‰ï¼š{', '.join(map(str, sorted(front_cold_numbers)))}")

        # ååŒºçƒ­å·å’Œå†·å·
        back_hot_numbers = [num for num, _ in back_number_freq.most_common(6)]
        back_cold_numbers = [num for num in range(1, 13) if back_number_freq.get(num, 0) <= 1]

        print(f"\nååŒºçƒ­å·ï¼ˆTop 6ï¼‰ï¼š{', '.join(map(str, back_hot_numbers))}")
        print(f"ååŒºå†·å·ï¼ˆå‡ºç°â‰¤1æ¬¡ï¼‰ï¼š{', '.join(map(str, sorted(back_cold_numbers)))}")

        return front_number_freq, back_number_freq

    def predict_lottery_numbers(self):
        """é¢„æµ‹å¤§ä¹é€å·ç """
        if self.df.empty:
            print("æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œå·ç é¢„æµ‹")
            return None, None

        print("\n=== æ™ºèƒ½å·ç é¢„æµ‹ ===")

        # è·å–å†å²é¢‘ç‡
        front_freq, back_freq = self.analyze_number_frequency(top_n=15)

        # æœ€è¿‘20æœŸè¶‹åŠ¿åˆ†æ
        recent_df = self.df.tail(20)
        recent_front_numbers = []
        recent_back_numbers = []

        for _, row in recent_df.iterrows():
            front_numbers = row['å‰åŒºå·ç '].split()
            back_numbers = row['ååŒºå·ç '].split()
            recent_front_numbers.extend([int(num) for num in front_numbers])
            recent_back_numbers.extend([int(num) for num in back_numbers])

        recent_front_freq = Counter(recent_front_numbers)
        recent_back_freq = Counter(recent_back_numbers)

        # ç»¼åˆè¯„åˆ†ç®—æ³•
        def calculate_score(num, all_freq, recent_freq, is_front=True):
            max_num = 35 if is_front else 12

            # å†å²é¢‘ç‡æƒé‡ (40%)
            total_appearances = sum(all_freq.values())
            historical_score = (all_freq.get(num, 0) / total_appearances) * 40 if total_appearances > 0 else 0

            # æœ€è¿‘è¶‹åŠ¿æƒé‡ (30%)
            recent_total = sum(recent_freq.values())
            recent_score = (recent_freq.get(num, 0) / recent_total) * 30 if recent_total > 0 else 0

            # å¹³è¡¡æ€§æƒé‡ (20%)
            avg_freq = total_appearances / max_num if total_appearances > 0 else 0
            current_freq = all_freq.get(num, 0)
            balance_score = 20 - abs(current_freq - avg_freq) * 2
            balance_score = max(0, balance_score)

            # éšæœºå› å­ (10%)
            random_score = random.uniform(0, 10)

            return historical_score + recent_score + balance_score + random_score

        # è®¡ç®—å‰åŒºå·ç å¾—åˆ†
        front_scores = {}
        for num in range(1, 36):
            score = calculate_score(num, front_freq, recent_front_freq, True)
            front_scores[num] = score

        # è®¡ç®—ååŒºå·ç å¾—åˆ†
        back_scores = {}
        for num in range(1, 13):
            score = calculate_score(num, back_freq, recent_back_freq, False)
            back_scores[num] = score

        # é€‰æ‹©å‰åŒºå·ç ï¼ˆç¡®ä¿å¥‡å¶å’Œå¤§å°å·å¹³è¡¡ï¼‰
        sorted_front = sorted(front_scores.items(), key=lambda x: x[1], reverse=True)

        predicted_front = []
        odd_count = 0
        even_count = 0
        small_count = 0
        big_count = 0

        for num, score in sorted_front:
            if len(predicted_front) >= 5:
                break

            is_odd = num % 2 == 1
            is_small = num <= 17

            # æ§åˆ¶å¥‡å¶æ¯”ä¾‹ï¼ˆå»ºè®®2-3ä¸ªå¥‡æ•°ï¼‰
            if is_odd and odd_count >= 3:
                continue
            if not is_odd and even_count >= 3:
                continue

            # æ§åˆ¶å¤§å°å·æ¯”ä¾‹ï¼ˆå»ºè®®2-3ä¸ªå°å·ï¼‰
            if is_small and small_count >= 3:
                continue
            if not is_small and big_count >= 3:
                continue

            predicted_front.append(num)
            if is_odd:
                odd_count += 1
            else:
                even_count += 1
            if is_small:
                small_count += 1
            else:
                big_count += 1

        # å¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„å·ç ï¼Œè¡¥å……æœ€é«˜åˆ†çš„å·ç 
        if len(predicted_front) < 5:
            for num, score in sorted_front:
                if num not in predicted_front:
                    predicted_front.append(num)
                    if len(predicted_front) >= 5:
                        break

        # é€‰æ‹©ååŒºå·ç 
        sorted_back = sorted(back_scores.items(), key=lambda x: x[1], reverse=True)
        predicted_back = [num for num, score in sorted_back[:2]]

        # æ ¼å¼åŒ–è¾“å‡º
        predicted_front_str = [f"{num:02d}" for num in sorted(predicted_front)]
        predicted_back_str = [f"{num:02d}" for num in sorted(predicted_back)]

        print("æ¨èå·ç ç»„åˆï¼š")
        print(f"å‰åŒºï¼š{' '.join(predicted_front_str)}")
        print(f"ååŒºï¼š{' '.join(predicted_back_str)}")

        # åˆ†ææ¨èå·ç çš„ç‰¹å¾
        odd_count = sum(1 for num in predicted_front if num % 2 == 1)
        small_count = sum(1 for num in predicted_front if num <= 17)

        print(f"\nå·ç ç‰¹å¾åˆ†æï¼š")
        print(f"å¥‡å¶æ¯”ä¾‹ï¼š{odd_count}å¥‡{5-odd_count}å¶")
        print(f"å¤§å°æ¯”ä¾‹ï¼š{small_count}å°{5-small_count}å¤§")

        # ç”Ÿæˆå¤šç»„å¤‡é€‰å·ç 
        print(f"\n=== å¤‡é€‰å·ç ç»„åˆ ===")
        for i in range(3):
            # åŸºäºæ™ºèƒ½é¢„æµ‹ç”Ÿæˆå¤‡é€‰ç»„åˆ
            backup_front = random.sample([num for num, _ in sorted_front[:15]], 5)
            backup_back = random.sample([num for num, _ in sorted_back[:8]], 2)

            front_str = [f"{num:02d}" for num in sorted(backup_front)]
            back_str = [f"{num:02d}" for num in sorted(backup_back)]

            print(f"å¤‡é€‰{i+1}ï¼šå‰åŒº {' '.join(front_str)} | ååŒº {' '.join(back_str)}")

        return predicted_front, predicted_back

    def analyze_weekday_patterns(self):
        """åˆ†æä¸åŒå¼€å¥–æ—¥çš„å·ç åˆ†å¸ƒå’Œé”€å”®é¢ç‰¹å¾"""
        if self.df.empty:
            print("æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
            return

        print("\n=== ä¸åŒå¼€å¥–æ—¥åˆ†æ ===")

        # ç­›é€‰å‘¨ä¸€ã€å‘¨ä¸‰ã€å‘¨å…­çš„æ•°æ®
        target_days = ['å‘¨ä¸€', 'å‘¨ä¸‰', 'å‘¨å…­']
        weekday_data = {}

        for day in target_days:
            day_df = self.df[self.df['ä¸­æ–‡æ˜ŸæœŸ'] == day]
            if not day_df.empty:
                weekday_data[day] = day_df

        if not weekday_data:
            print("æ²¡æœ‰æ‰¾åˆ°å‘¨ä¸€ã€å‘¨ä¸‰ã€å‘¨å…­çš„å¼€å¥–æ•°æ®")
            return

        # åˆ›å»ºå¯è§†åŒ–
        plt.figure(figsize=(20, 12))

        # é”€å”®é¢å¯¹æ¯”
        plt.subplot(2, 3, 1)
        sales_by_day = []
        day_labels = []
        for day, data in weekday_data.items():
            sales_by_day.append(data['é”€å”®é¢'].tolist())
            day_labels.append(f"{day}({len(data)}æœŸ)")

        plt.boxplot(sales_by_day, labels=day_labels)
        plt.title('ä¸åŒå¼€å¥–æ—¥é”€å”®é¢åˆ†å¸ƒå¯¹æ¯”')
        plt.ylabel('é”€å”®é¢ï¼ˆå…ƒï¼‰')
        plt.xticks(rotation=45)
        plt.grid(True, alpha=0.3)

        # å‰åŒºå·ç é¢‘ç‡å¯¹æ¯”
        plt.subplot(2, 3, 2)
        front_freq_by_day = {}
        for day, data in weekday_data.items():
            all_front = []
            for _, row in data.iterrows():
                front_numbers = row['å‰åŒºå·ç '].split()
                all_front.extend([int(num) for num in front_numbers])
            front_freq_by_day[day] = Counter(all_front)

        # è®¡ç®—æ¯ä¸ªå·ç åœ¨ä¸åŒæ—¥æœŸçš„å‡ºç°é¢‘ç‡
        all_front_numbers = list(range(1, 36))
        freq_matrix = []
        for num in all_front_numbers[:15]:  # åªæ˜¾ç¤ºå‰15ä¸ªå·ç 
            freq_row = []
            for day in target_days:
                if day in front_freq_by_day:
                    freq_row.append(front_freq_by_day[day].get(num, 0))
                else:
                    freq_row.append(0)
            freq_matrix.append(freq_row)

        freq_matrix = np.array(freq_matrix)
        sns.heatmap(freq_matrix,
                   xticklabels=[f"{day}({len(weekday_data.get(day, []))}æœŸ)" for day in target_days],
                   yticklabels=[f"{num:02d}" for num in all_front_numbers[:15]],
                   annot=True, fmt='d', cmap='Blues')
        plt.title('å‰åŒºå·ç é¢‘ç‡å¯¹æ¯”ï¼ˆå‰15ä¸ªå·ç ï¼‰')

        # ååŒºå·ç é¢‘ç‡å¯¹æ¯”
        plt.subplot(2, 3, 3)
        back_freq_by_day = {}
        for day, data in weekday_data.items():
            all_back = []
            for _, row in data.iterrows():
                back_numbers = row['ååŒºå·ç '].split()
                all_back.extend([int(num) for num in back_numbers])
            back_freq_by_day[day] = Counter(all_back)

        # è®¡ç®—ååŒºå·ç é¢‘ç‡çŸ©é˜µ
        all_back_numbers = list(range(1, 13))
        back_freq_matrix = []
        for num in all_back_numbers:
            freq_row = []
            for day in target_days:
                if day in back_freq_by_day:
                    freq_row.append(back_freq_by_day[day].get(num, 0))
                else:
                    freq_row.append(0)
            back_freq_matrix.append(freq_row)

        back_freq_matrix = np.array(back_freq_matrix)
        sns.heatmap(back_freq_matrix,
                   xticklabels=[f"{day}({len(weekday_data.get(day, []))}æœŸ)" for day in target_days],
                   yticklabels=[f"{num:02d}" for num in all_back_numbers],
                   annot=True, fmt='d', cmap='Reds')
        plt.title('ååŒºå·ç é¢‘ç‡å¯¹æ¯”')

        # å¥‡å¶æ¯”ä¾‹åˆ†æ
        plt.subplot(2, 3, 4)
        odd_even_patterns = {}
        for day, data in weekday_data.items():
            patterns = []
            for _, row in data.iterrows():
                front_numbers = [int(num) for num in row['å‰åŒºå·ç '].split()]
                odd_count = sum(1 for num in front_numbers if num % 2 == 1)
                patterns.append(f"{odd_count}å¥‡{5-odd_count}å¶")
            odd_even_patterns[day] = Counter(patterns)

        # ç»˜åˆ¶å¥‡å¶æ¯”ä¾‹åˆ†å¸ƒ
        pattern_types = ['1å¥‡4å¶', '2å¥‡3å¶', '3å¥‡2å¶', '4å¥‡1å¶', '5å¥‡0å¶']
        x_pos = np.arange(len(pattern_types))
        bar_width = 0.25

        for i, (day, patterns) in enumerate(odd_even_patterns.items()):
            counts = [patterns.get(pattern, 0) for pattern in pattern_types]
            plt.bar(x_pos + i * bar_width, counts, bar_width, label=day)

        plt.xlabel('å¥‡å¶æ¯”ä¾‹')
        plt.ylabel('å‡ºç°æ¬¡æ•°')
        plt.title('ä¸åŒå¼€å¥–æ—¥å¥‡å¶æ¯”ä¾‹åˆ†å¸ƒ')
        plt.xticks(x_pos + bar_width, pattern_types, rotation=45)
        plt.legend()
        plt.grid(axis='y', alpha=0.3)

        # å¤§å°å·æ¯”ä¾‹åˆ†æ
        plt.subplot(2, 3, 5)
        size_patterns = {}
        for day, data in weekday_data.items():
            patterns = []
            for _, row in data.iterrows():
                front_numbers = [int(num) for num in row['å‰åŒºå·ç '].split()]
                small_count = sum(1 for num in front_numbers if num <= 17)
                patterns.append(f"{small_count}å°{5-small_count}å¤§")
            size_patterns[day] = Counter(patterns)

        # ç»˜åˆ¶å¤§å°å·æ¯”ä¾‹åˆ†å¸ƒ
        size_types = ['1å°4å¤§', '2å°3å¤§', '3å°2å¤§', '4å°1å¤§', '5å°0å¤§']
        x_pos = np.arange(len(size_types))

        for i, (day, patterns) in enumerate(size_patterns.items()):
            counts = [patterns.get(pattern, 0) for pattern in size_types]
            plt.bar(x_pos + i * bar_width, counts, bar_width, label=day)

        plt.xlabel('å¤§å°å·æ¯”ä¾‹')
        plt.ylabel('å‡ºç°æ¬¡æ•°')
        plt.title('ä¸åŒå¼€å¥–æ—¥å¤§å°å·æ¯”ä¾‹åˆ†å¸ƒ')
        plt.xticks(x_pos + bar_width, size_types, rotation=45)
        plt.legend()
        plt.grid(axis='y', alpha=0.3)

        # ç»Ÿè®¡ä¿¡æ¯å¯¹æ¯”
        plt.subplot(2, 3, 6)
        stats_text = ""
        for day, data in weekday_data.items():
            avg_sales = data['é”€å”®é¢'].mean()
            period_count = len(data)
            stats_text += f"{day}å¼€å¥–ç»Ÿè®¡ï¼š\n"
            stats_text += f"  æœŸæ•°ï¼š{period_count}æœŸ\n"
            stats_text += f"  å¹³å‡é”€å”®é¢ï¼š{avg_sales:.0f}å…ƒ\n\n"

        plt.text(0.1, 0.5, stats_text, fontsize=12, verticalalignment='center')
        plt.axis('off')
        plt.title('ç»Ÿè®¡ä¿¡æ¯å¯¹æ¯”')

        plt.tight_layout()
        plt.show()

        # æ‰“å°è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        print("=== ä¸åŒå¼€å¥–æ—¥ç»Ÿè®¡å¯¹æ¯” ===")
        for day, data in weekday_data.items():
            print(f"\n{day}å¼€å¥–ï¼ˆ{len(data)}æœŸï¼‰ï¼š")
            print(f"  å¹³å‡é”€å”®é¢ï¼š{data['é”€å”®é¢'].mean():.2f}å…ƒ")
            print(f"  é”€å”®é¢æ ‡å‡†å·®ï¼š{data['é”€å”®é¢'].std():.2f}å…ƒ")

            # å‰åŒºçƒ­é—¨å·ç 
            all_front = []
            for _, row in data.iterrows():
                front_numbers = row['å‰åŒºå·ç '].split()
                all_front.extend([int(num) for num in front_numbers])
            front_freq = Counter(all_front)
            hot_front = [str(num) for num, _ in front_freq.most_common(5)]
            print(f"  å‰åŒºçƒ­é—¨å·ç ï¼š{', '.join(hot_front)}")

            # ååŒºçƒ­é—¨å·ç 
            all_back = []
            for _, row in data.iterrows():
                back_numbers = row['ååŒºå·ç '].split()
                all_back.extend([int(num) for num in back_numbers])
            back_freq = Counter(all_back)
            hot_back = [str(num) for num, _ in back_freq.most_common(3)]
            print(f"  ååŒºçƒ­é—¨å·ç ï¼š{', '.join(hot_back)}")

    def analyze_expert_data(self):
        """åˆ†æçœŸå®ä¸“å®¶æ•°æ®"""
        print("\n=== ä¸“å®¶æ•°æ®åˆ†æ ===")

        # åˆ›å»ºä¸“å®¶çˆ¬è™«å®ä¾‹
        expert_spider = ExpertSpider()

        # è·å–ä¸“å®¶æ•°æ®ï¼ˆ30ä½ä¸“å®¶ï¼‰
        experts_data = expert_spider.crawl_experts(target_count=30)

        if not experts_data:
            print("æœªèƒ½è·å–ä¸“å®¶æ•°æ®")
            return None

        # è½¬æ¢ä¸ºDataFrame
        expert_df = pd.DataFrame(experts_data)

        print(f"æˆåŠŸè·å–{len(expert_df)}ä½ä¸“å®¶æ•°æ®")

        # åˆ›å»ºè¯¦ç»†çš„å¯è§†åŒ–åˆ†æ
        plt.figure(figsize=(20, 15))

        # 1. ä¸“å®¶å½©é¾„åˆ†å¸ƒ
        plt.subplot(3, 3, 1)
        plt.hist(expert_df['å½©é¾„'], bins=15, alpha=0.7, edgecolor='black', color='skyblue')
        plt.title('ä¸“å®¶å½©é¾„åˆ†å¸ƒ')
        plt.xlabel('å½©é¾„ï¼ˆå¹´ï¼‰')
        plt.ylabel('ä¸“å®¶æ•°é‡')
        plt.grid(axis='y', alpha=0.3)

        # 2. æ–‡ç« æ•°é‡åˆ†å¸ƒ
        plt.subplot(3, 3, 2)
        plt.hist(expert_df['æ–‡ç« æ•°é‡'], bins=15, alpha=0.7, edgecolor='black', color='orange')
        plt.title('ä¸“å®¶å‘æ–‡é‡åˆ†å¸ƒ')
        plt.xlabel('æ–‡ç« æ•°é‡ï¼ˆç¯‡ï¼‰')
        plt.ylabel('ä¸“å®¶æ•°é‡')
        plt.grid(axis='y', alpha=0.3)

        # 3. ä¸“å®¶ç­‰çº§åˆ†å¸ƒ
        plt.subplot(3, 3, 3)
        level_counts = expert_df['ç­‰çº§'].value_counts()
        colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']
        plt.pie(level_counts.values, labels=level_counts.index, autopct='%1.1f%%', colors=colors)
        plt.title('ä¸“å®¶ç­‰çº§åˆ†å¸ƒ')

        # 4. å¤§ä¹é€ä¸€ç­‰å¥–åˆ†å¸ƒ
        plt.subplot(3, 3, 4)
        first_prize_counts = expert_df['å¤§ä¹é€ä¸€ç­‰å¥–'].value_counts().sort_index()
        plt.bar(first_prize_counts.index, first_prize_counts.values, alpha=0.7, color='gold')
        plt.title('å¤§ä¹é€ä¸€ç­‰å¥–ä¸­å¥–æ¬¡æ•°åˆ†å¸ƒ')
        plt.xlabel('ä¸€ç­‰å¥–æ¬¡æ•°')
        plt.ylabel('ä¸“å®¶æ•°é‡')
        plt.grid(axis='y', alpha=0.3)

        # 5. å½©é¾„ä¸ä¸­å¥–ç‡å…³ç³»
        plt.subplot(3, 3, 5)
        plt.scatter(expert_df['å½©é¾„'], expert_df['ä¸­å¥–ç‡'], alpha=0.7, s=60)
        plt.xlabel('å½©é¾„ï¼ˆå¹´ï¼‰')
        plt.ylabel('ä¸­å¥–ç‡ï¼ˆ%ï¼‰')
        plt.title('å½©é¾„ä¸ä¸­å¥–ç‡å…³ç³»')
        plt.grid(True, alpha=0.3)

        # è®¡ç®—ç›¸å…³ç³»æ•°
        correlation_age = expert_df['å½©é¾„'].corr(expert_df['ä¸­å¥–ç‡'])
        plt.text(0.05, 0.95, f'ç›¸å…³ç³»æ•°: {correlation_age:.3f}', transform=plt.gca().transAxes,
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

        # 6. å‘æ–‡é‡ä¸ä¸­å¥–ç‡å…³ç³»
        plt.subplot(3, 3, 6)
        plt.scatter(expert_df['æ–‡ç« æ•°é‡'], expert_df['ä¸­å¥–ç‡'], alpha=0.7, color='red', s=60)
        plt.xlabel('æ–‡ç« æ•°é‡ï¼ˆç¯‡ï¼‰')
        plt.ylabel('ä¸­å¥–ç‡ï¼ˆ%ï¼‰')
        plt.title('å‘æ–‡é‡ä¸ä¸­å¥–ç‡å…³ç³»')
        plt.grid(True, alpha=0.3)

        # è®¡ç®—ç›¸å…³ç³»æ•°
        correlation_articles = expert_df['æ–‡ç« æ•°é‡'].corr(expert_df['ä¸­å¥–ç‡'])
        plt.text(0.05, 0.95, f'ç›¸å…³ç³»æ•°: {correlation_articles:.3f}', transform=plt.gca().transAxes,
                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))

        # 7. ä¸åŒç­‰çº§ä¸“å®¶ä¸­å¥–ç‡å¯¹æ¯”
        plt.subplot(3, 3, 7)
        level_win_rates = []
        level_labels = []
        for level in expert_df['ç­‰çº§'].unique():
            level_data = expert_df[expert_df['ç­‰çº§'] == level]['ä¸­å¥–ç‡']
            if not level_data.empty:
                level_win_rates.append(level_data.tolist())
                level_labels.append(f"{level}({len(level_data)}äºº)")

        if level_win_rates:
            plt.boxplot(level_win_rates, labels=level_labels)
            plt.ylabel('ä¸­å¥–ç‡ï¼ˆ%ï¼‰')
            plt.title('ä¸åŒç­‰çº§ä¸“å®¶ä¸­å¥–ç‡åˆ†å¸ƒ')
            plt.xticks(rotation=45)
            plt.grid(axis='y', alpha=0.3)

        # 8. æ€»ä¸­å¥–æ¬¡æ•°åˆ†å¸ƒ
        plt.subplot(3, 3, 8)
        plt.hist(expert_df['æ€»ä¸­å¥–æ¬¡æ•°'], bins=20, alpha=0.7, edgecolor='black', color='lightgreen')
        plt.title('ä¸“å®¶æ€»ä¸­å¥–æ¬¡æ•°åˆ†å¸ƒ')
        plt.xlabel('æ€»ä¸­å¥–æ¬¡æ•°')
        plt.ylabel('ä¸“å®¶æ•°é‡')
        plt.grid(axis='y', alpha=0.3)

        # 9. ä¸­å¥–ç‡åˆ†å¸ƒ
        plt.subplot(3, 3, 9)
        plt.hist(expert_df['ä¸­å¥–ç‡'], bins=15, alpha=0.7, edgecolor='black', color='purple')
        plt.title('ä¸“å®¶ä¸­å¥–ç‡åˆ†å¸ƒ')
        plt.xlabel('ä¸­å¥–ç‡ï¼ˆ%ï¼‰')
        plt.ylabel('ä¸“å®¶æ•°é‡')
        plt.grid(axis='y', alpha=0.3)

        plt.tight_layout()
        plt.show()

        # åˆ›å»ºä¸“å®¶ä¸­å¥–æƒ…å†µè¯¦ç»†åˆ†æ
        plt.figure(figsize=(15, 10))

        # å„ç­‰çº§å¥–é¡¹åˆ†å¸ƒçƒ­åŠ›å›¾
        plt.subplot(2, 2, 1)
        prize_data = expert_df.groupby('ç­‰çº§')[['å¤§ä¹é€ä¸€ç­‰å¥–', 'å¤§ä¹é€äºŒç­‰å¥–', 'å¤§ä¹é€ä¸‰ç­‰å¥–']].sum()
        sns.heatmap(prize_data.T, annot=True, fmt='d', cmap='Reds', cbar_kws={'label': 'ä¸­å¥–æ¬¡æ•°'})
        plt.title('ä¸åŒç­‰çº§ä¸“å®¶å„å¥–é¡¹ä¸­å¥–æ¬¡æ•°')
        plt.xlabel('ä¸“å®¶ç­‰çº§')
        plt.ylabel('å¥–é¡¹ç±»å‹')

        # å½©é¾„vsæ€»ä¸­å¥–æ¬¡æ•°æ•£ç‚¹å›¾
        plt.subplot(2, 2, 2)
        colors = expert_df['ç­‰çº§'].map({'åˆçº§': 'blue', 'ä¸­çº§': 'green', 'é«˜çº§': 'red', 'ç‰¹çº§': 'purple'})
        plt.scatter(expert_df['å½©é¾„'], expert_df['æ€»ä¸­å¥–æ¬¡æ•°'], c=colors, alpha=0.7, s=80)
        plt.xlabel('å½©é¾„ï¼ˆå¹´ï¼‰')
        plt.ylabel('æ€»ä¸­å¥–æ¬¡æ•°')
        plt.title('å½©é¾„ä¸æ€»ä¸­å¥–æ¬¡æ•°å…³ç³»ï¼ˆæŒ‰ç­‰çº§åˆ†è‰²ï¼‰')
        plt.grid(True, alpha=0.3)

        # åˆ›å»ºå›¾ä¾‹
        for level, color in [('åˆçº§', 'blue'), ('ä¸­çº§', 'green'), ('é«˜çº§', 'red'), ('ç‰¹çº§', 'purple')]:
            plt.scatter([], [], c=color, alpha=0.7, s=80, label=level)
        plt.legend()

        # æ–‡ç« æ•°é‡vsä¸­å¥–ç‡æ•£ç‚¹å›¾ï¼ˆæŒ‰å½©é¾„åˆ†è‰²ï¼‰
        plt.subplot(2, 2, 3)
        scatter = plt.scatter(expert_df['æ–‡ç« æ•°é‡'], expert_df['ä¸­å¥–ç‡'],
                            c=expert_df['å½©é¾„'], cmap='viridis', alpha=0.7, s=80)
        plt.xlabel('æ–‡ç« æ•°é‡ï¼ˆç¯‡ï¼‰')
        plt.ylabel('ä¸­å¥–ç‡ï¼ˆ%ï¼‰')
        plt.title('æ–‡ç« æ•°é‡ä¸ä¸­å¥–ç‡å…³ç³»ï¼ˆå½©é¾„ç€è‰²ï¼‰')
        plt.colorbar(scatter, label='å½©é¾„ï¼ˆå¹´ï¼‰')
        plt.grid(True, alpha=0.3)

        # ä¸“å®¶ç»¼åˆå®åŠ›è¯„åˆ†
        plt.subplot(2, 2, 4)
        # è®¡ç®—ç»¼åˆè¯„åˆ†ï¼šå½©é¾„æƒé‡30% + ä¸­å¥–ç‡æƒé‡40% + æ–‡ç« æ•°é‡æƒé‡20% + ç­‰çº§æƒé‡10%
        level_score = expert_df['ç­‰çº§'].map({'åˆçº§': 1, 'ä¸­çº§': 2, 'é«˜çº§': 3, 'ç‰¹çº§': 4})

        expert_df['ç»¼åˆè¯„åˆ†'] = (
            (expert_df['å½©é¾„'] / expert_df['å½©é¾„'].max()) * 30 +
            (expert_df['ä¸­å¥–ç‡'] / expert_df['ä¸­å¥–ç‡'].max()) * 40 +
            (expert_df['æ–‡ç« æ•°é‡'] / expert_df['æ–‡ç« æ•°é‡'].max()) * 20 +
            (level_score / level_score.max()) * 10
        )

        plt.hist(expert_df['ç»¼åˆè¯„åˆ†'], bins=15, alpha=0.7, edgecolor='black', color='cyan')
        plt.title('ä¸“å®¶ç»¼åˆå®åŠ›è¯„åˆ†åˆ†å¸ƒ')
        plt.xlabel('ç»¼åˆè¯„åˆ†')
        plt.ylabel('ä¸“å®¶æ•°é‡')
        plt.grid(axis='y', alpha=0.3)

        plt.tight_layout()
        plt.show()

        # æ‰“å°è¯¦ç»†ç»Ÿè®¡æŠ¥å‘Š
        print("\n" + "="*60)
        print("                ä¸“å®¶æ•°æ®ç»Ÿè®¡åˆ†ææŠ¥å‘Š")
        print("="*60)

        print(f"ä¸“å®¶æ€»æ•°ï¼š{len(expert_df)}äºº")
        print(f"æ•°æ®è·å–æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        print(f"\n=== åŸºæœ¬å±æ€§ç»Ÿè®¡ ===")
        print(f"å¹³å‡å½©é¾„ï¼š{expert_df['å½©é¾„'].mean():.1f}å¹´ï¼ˆæ ‡å‡†å·®ï¼š{expert_df['å½©é¾„'].std():.1f}å¹´ï¼‰")
        print(f"å½©é¾„èŒƒå›´ï¼š{expert_df['å½©é¾„'].min()}å¹´ - {expert_df['å½©é¾„'].max()}å¹´")
        print(f"å¹³å‡å‘æ–‡é‡ï¼š{expert_df['æ–‡ç« æ•°é‡'].mean():.0f}ç¯‡ï¼ˆæ ‡å‡†å·®ï¼š{expert_df['æ–‡ç« æ•°é‡'].std():.0f}ç¯‡ï¼‰")
        print(f"å‘æ–‡é‡èŒƒå›´ï¼š{expert_df['æ–‡ç« æ•°é‡'].min()}ç¯‡ - {expert_df['æ–‡ç« æ•°é‡'].max()}ç¯‡")

        print(f"\n=== ä¸­å¥–æƒ…å†µç»Ÿè®¡ ===")
        print(f"å¤§ä¹é€ä¸€ç­‰å¥–æ€»è®¡ï¼š{expert_df['å¤§ä¹é€ä¸€ç­‰å¥–'].sum()}æ¬¡")
        print(f"å¤§ä¹é€äºŒç­‰å¥–æ€»è®¡ï¼š{expert_df['å¤§ä¹é€äºŒç­‰å¥–'].sum()}æ¬¡")
        print(f"å¤§ä¹é€ä¸‰ç­‰å¥–æ€»è®¡ï¼š{expert_df['å¤§ä¹é€ä¸‰ç­‰å¥–'].sum()}æ¬¡")
        print(f"å¹³å‡ä¸­å¥–ç‡ï¼š{expert_df['ä¸­å¥–ç‡'].mean():.2f}%ï¼ˆæ ‡å‡†å·®ï¼š{expert_df['ä¸­å¥–ç‡'].std():.2f}%ï¼‰")
        print(f"æœ€é«˜ä¸­å¥–ç‡ï¼š{expert_df['ä¸­å¥–ç‡'].max():.2f}%")
        print(f"æœ€ä½ä¸­å¥–ç‡ï¼š{expert_df['ä¸­å¥–ç‡'].min():.2f}%")

        print(f"\n=== ä¸åŒç­‰çº§ä¸“å®¶ç»Ÿè®¡ ===")
        for level in expert_df['ç­‰çº§'].unique():
            level_data = expert_df[expert_df['ç­‰çº§'] == level]
            if not level_data.empty:
                print(f"{level}ä¸“å®¶ï¼ˆ{len(level_data)}äººï¼‰ï¼š")
                print(f"  å¹³å‡å½©é¾„ï¼š{level_data['å½©é¾„'].mean():.1f}å¹´")
                print(f"  å¹³å‡å‘æ–‡é‡ï¼š{level_data['æ–‡ç« æ•°é‡'].mean():.0f}ç¯‡")
                print(f"  å¹³å‡ä¸­å¥–ç‡ï¼š{level_data['ä¸­å¥–ç‡'].mean():.2f}%")
                print(f"  ä¸€ç­‰å¥–æ€»æ•°ï¼š{level_data['å¤§ä¹é€ä¸€ç­‰å¥–'].sum()}æ¬¡")

        print(f"\n=== ç›¸å…³æ€§åˆ†æ ===")
        print(f"å½©é¾„ä¸ä¸­å¥–ç‡ç›¸å…³ç³»æ•°ï¼š{correlation_age:.3f}")
        print(f"å‘æ–‡é‡ä¸ä¸­å¥–ç‡ç›¸å…³ç³»æ•°ï¼š{correlation_articles:.3f}")

        # è®¡ç®—æ›´å¤šç›¸å…³æ€§
        corr_age_total = expert_df['å½©é¾„'].corr(expert_df['æ€»ä¸­å¥–æ¬¡æ•°'])
        corr_articles_total = expert_df['æ–‡ç« æ•°é‡'].corr(expert_df['æ€»ä¸­å¥–æ¬¡æ•°'])
        print(f"å½©é¾„ä¸æ€»ä¸­å¥–æ¬¡æ•°ç›¸å…³ç³»æ•°ï¼š{corr_age_total:.3f}")
        print(f"å‘æ–‡é‡ä¸æ€»ä¸­å¥–æ¬¡æ•°ç›¸å…³ç³»æ•°ï¼š{corr_articles_total:.3f}")

        print(f"\n=== Top 10 ä¸“å®¶æ’è¡Œæ¦œ ===")
        # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
        top_experts = expert_df.nlargest(10, 'ç»¼åˆè¯„åˆ†')
        for i, (_, expert) in enumerate(top_experts.iterrows(), 1):
            print(f"{i:2d}. {expert['name']}ï¼š")
            print(f"    ç»¼åˆè¯„åˆ†ï¼š{expert['ç»¼åˆè¯„åˆ†']:.1f} | å½©é¾„ï¼š{expert['å½©é¾„']}å¹´ | ä¸­å¥–ç‡ï¼š{expert['ä¸­å¥–ç‡']:.2f}%")
            print(f"    å‘æ–‡ï¼š{expert['æ–‡ç« æ•°é‡']}ç¯‡ | ç­‰çº§ï¼š{expert['ç­‰çº§']} | ä¸€ç­‰å¥–ï¼š{expert['å¤§ä¹é€ä¸€ç­‰å¥–']}æ¬¡")

        print(f"\n=== ä¸­å¥–æ•ˆç‡æœ€é«˜ä¸“å®¶ ===")
        # æŒ‰ä¸­å¥–ç‡æ’åº
        top_winners = expert_df.nlargest(5, 'ä¸­å¥–ç‡')
        for i, (_, expert) in enumerate(top_winners.iterrows(), 1):
            print(f"{i}. {expert['name']}ï¼šä¸­å¥–ç‡{expert['ä¸­å¥–ç‡']:.2f}%ï¼Œå½©é¾„{expert['å½©é¾„']}å¹´ï¼Œä¸€ç­‰å¥–{expert['å¤§ä¹é€ä¸€ç­‰å¥–']}æ¬¡")

        # ä¿å­˜ä¸“å®¶æ•°æ®åˆ†æç»“æœ
        try:
            expert_df.to_csv('expert_analysis_result.csv', index=False, encoding='utf-8-sig')
            print(f"\nä¸“å®¶åˆ†æç»“æœå·²ä¿å­˜åˆ°ï¼šexpert_analysis_result.csv")
        except Exception as e:
            print(f"ä¿å­˜åˆ†æç»“æœå¤±è´¥ï¼š{e}")

        print("\n" + "="*60)
        print("                ä¸“å®¶æ•°æ®åˆ†æå®Œæˆ")
        print("="*60)

        return expert_df

    def save_data(self, filename='dlt_data.csv'):
        """ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶"""
        try:
            self.df.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f"æ•°æ®å·²ä¿å­˜åˆ°ï¼š{filename}")
        except Exception as e:
            print(f"ä¿å­˜æ•°æ®å¤±è´¥ï¼š{e}")

def show_menu():
    """æ˜¾ç¤ºèœå•"""
    print("\n" + "="*60)
    print("               å¤§ä¹é€æ•°æ®åˆ†æç³»ç»Ÿ")
    print("="*60)
    print("è¯·é€‰æ‹©åŠŸèƒ½ï¼š")
    print("1. é”€å”®é¢è¶‹åŠ¿åˆ†æä¸é¢„æµ‹")
    print("2. å·ç é¢‘ç‡ç»Ÿè®¡ä¸å¯è§†åŒ–åˆ†æ")
    print("3. æ™ºèƒ½å·ç é¢„æµ‹æ¨è")
    print("4. ä¸åŒå¼€å¥–æ—¥å¯¹æ¯”åˆ†æ")
    print("5. ä¸“å®¶æ•°æ®ç»Ÿè®¡åˆ†æ")
    print("6. ç»¼åˆåˆ†ææŠ¥å‘Š")
    print("0. é€€å‡ºç³»ç»Ÿ")
    print("="*60)

def main():
    """ä¸»å‡½æ•°"""
    print("=== å¤§ä¹é€æ•°æ®åˆ†æç³»ç»Ÿå¯åŠ¨ ===")

    # åŠ è½½æ•°æ®
    try:
        print("æ­£åœ¨åŠ è½½æ•°æ®...")
        # ä¼˜å…ˆä»CSVæ–‡ä»¶åŠ è½½
        try:
            df_existing = pd.read_csv('å¤§ä¹é€å¼€å¥–æ•°æ®.csv', encoding='utf-8-sig')
            if not df_existing.empty:
                print(f"ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®æˆåŠŸï¼Œå…±{len(df_existing)}æ¡è®°å½•")
                lottery_data = df_existing.to_dict('records')
            else:
                raise FileNotFoundError("CSVæ–‡ä»¶ä¸ºç©º")
        except:
            # å¦‚æœCSVæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œä»çˆ¬è™«è·å–æ•°æ®
            print("CSVæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œå°è¯•è·å–æ–°æ•°æ®...")
            spider = DLTSpider()
            lottery_data = spider.crawl_lottery_data(target_periods=100)
            if not lottery_data:
                print("æ— æ³•è·å–æ•°æ®ï¼Œç¨‹åºé€€å‡º")
                return

        # åˆ›å»ºåˆ†æå™¨å®ä¾‹
        analyzer = DLTAnalyzer(lottery_data)
        analyzer.save_data('å¤§ä¹é€å¼€å¥–æ•°æ®.csv')

        # ä¸»å¾ªç¯
        while True:
            show_menu()
            try:
                choice = input("è¯·è¾“å…¥é€‰æ‹©ï¼ˆ0-6ï¼‰ï¼š").strip()

                if choice == '0':
                    print("æ„Ÿè°¢ä½¿ç”¨å¤§ä¹é€æ•°æ®åˆ†æç³»ç»Ÿï¼")
                    break
                elif choice == '1':
                    print("\næ‰§è¡Œé”€å”®é¢è¶‹åŠ¿åˆ†æä¸é¢„æµ‹...")
                    analyzer.analyze_sales_trend()
                elif choice == '2':
                    print("\næ‰§è¡Œå·ç é¢‘ç‡ç»Ÿè®¡ä¸å¯è§†åŒ–åˆ†æ...")
                    analyzer.analyze_number_frequency(top_n=10)
                elif choice == '3':
                    print("\næ‰§è¡Œæ™ºèƒ½å·ç é¢„æµ‹...")
                    predicted_front, predicted_back = analyzer.predict_lottery_numbers()
                    if predicted_front and predicted_back:
                        front_str = [f"{num:02d}" for num in sorted(predicted_front)]
                        back_str = [f"{num:02d}" for num in sorted(predicted_back)]
                        print(f"\nğŸ¯ 2025å¹´7æœˆ1æ—¥åæœ€æ–°ä¸€æœŸæ¨èå·ç ï¼š")
                        print(f"å‰åŒºï¼š{' '.join(front_str)}")
                        print(f"ååŒºï¼š{' '.join(back_str)}")
                elif choice == '4':
                    print("\næ‰§è¡Œä¸åŒå¼€å¥–æ—¥å¯¹æ¯”åˆ†æ...")
                    analyzer.analyze_weekday_patterns()
                elif choice == '5':
                    print("\næ‰§è¡Œä¸“å®¶æ•°æ®ç»Ÿè®¡åˆ†æ...")
                    analyzer.analyze_expert_data()
                elif choice == '6':
                    print("\nç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š...")
                    # æ‰§è¡Œæ‰€æœ‰åˆ†æ
                    analyzer.analyze_sales_trend()
                    analyzer.analyze_number_frequency(top_n=10)
                    predicted_front, predicted_back = analyzer.predict_lottery_numbers()
                    analyzer.analyze_weekday_patterns()
                    analyzer.analyze_expert_data()

                    if predicted_front and predicted_back:
                        front_str = [f"{num:02d}" for num in sorted(predicted_front)]
                        back_str = [f"{num:02d}" for num in sorted(predicted_back)]
                        print(f"\nğŸ¯ æœ€ç»ˆæ¨èå·ç ï¼š")
                        print(f"å‰åŒºï¼š{' '.join(front_str)}")
                        print(f"ååŒºï¼š{' '.join(back_str)}")
                else:
                    print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥ï¼")

                input("\næŒ‰å›è½¦é”®ç»§ç»­...")

            except KeyboardInterrupt:
                print("\n\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
                break
            except Exception as e:
                print(f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{e}")
                input("æŒ‰å›è½¦é”®ç»§ç»­...")

    except Exception as e:
        print(f"ç¨‹åºå¯åŠ¨å¤±è´¥ï¼š{e}")


class ExpertSpider:
    def __init__(self):
        self.base_url = "https://www.cmzj.net/dlt/tickets"
        self.expert_base_url = "https://www.cmzj.net/expertItem"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
        }

    def get_expert_list(self, target_count=30):
        """è·å–ä¸“å®¶åˆ—è¡¨ï¼Œé€šè¿‡æ¢ä¸€æ‰¹æŒ‰é’®è·å–æ›´å¤šä¸“å®¶"""
        try:
            # é…ç½®æµè§ˆå™¨é€‰é¡¹
            options = webdriver.ChromeOptions()
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_experimental_option("excludeSwitches", ["enable-automation"])
            options.add_experimental_option('useAutomationExtension', False)

            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=options)
            driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

            print(f"æ­£åœ¨è®¿é—®ä¸“å®¶é¡µé¢: {self.base_url}")
            driver.get(self.base_url)
            time.sleep(5)

            all_experts = []
            rounds = 0
            max_rounds = 6

            while len(all_experts) < target_count and rounds < max_rounds:
                print(f"ç¬¬{rounds + 1}è½®è·å–ä¸“å®¶ä¿¡æ¯...")

                # ç­‰å¾…ä¸“å®¶åˆ—è¡¨åŠ è½½
                try:
                    WebDriverWait(driver, 10).until(
                        EC.presence_of_element_located((By.CLASS_NAME, "items"))
                    )
                    time.sleep(2)
                except:
                    print("ä¸“å®¶åˆ—è¡¨åŠ è½½è¶…æ—¶")
                    break

                # è·å–å½“å‰é¡µé¢çš„å‰8ä¸ªä¸“å®¶åç§°
                expert_names = []
                try:
                    experts = driver.find_elements(By.CLASS_NAME, "items")
                    expert_items = experts[:8]  # åªå–å‰8ä¸ªä½œä¸ºä¸“å®¶

                    print(f"æ‰¾åˆ° {len(expert_items)} ä¸ªä¸“å®¶item")

                    for expert in expert_items:
                        try:
                            name_element = expert.find_element(By.CLASS_NAME, "okami-name")
                            expert_name = name_element.text.strip()

                            # æ£€æŸ¥æ˜¯å¦å·²ç»è·å–è¿‡è¯¥ä¸“å®¶
                            if expert_name and expert_name not in [e['name'] for e in all_experts]:
                                expert_names.append(expert_name)

                        except Exception as e:
                            print(f"æå–ä¸“å®¶åç§°æ—¶å‡ºé”™: {e}")
                            continue

                    print(f"æœ¬è½®å‡†å¤‡è·å– {len(expert_names)} ä½æ–°ä¸“å®¶æ•°æ®")

                except Exception as e:
                    print(f"è·å–ä¸“å®¶åˆ—è¡¨æ—¶å‡ºé”™: {e}")
                    break

                # é€ä¸ªç‚¹å‡»ä¸“å®¶è·å–è¯¦ç»†ä¿¡æ¯
                for i, expert_name in enumerate(expert_names):
                    try:
                        if len(all_experts) >= target_count:
                            break

                        print(f"æ­£åœ¨è·å–ç¬¬{i + 1}ä½ä¸“å®¶ï¼š{expert_name}")

                        # ç¡®ä¿åœ¨ä¸»é¡µé¢ï¼Œé‡æ–°æŸ¥æ‰¾ä¸“å®¶å…ƒç´ 
                        current_url = driver.current_url
                        if self.base_url not in current_url:
                            print("ä¸åœ¨ä¸»é¡µé¢ï¼Œè¿”å›ä¸»é¡µé¢")
                            driver.get(self.base_url)
                            time.sleep(3)
                            WebDriverWait(driver, 10).until(
                                EC.presence_of_element_located((By.CLASS_NAME, "items"))
                            )
                            time.sleep(2)

                        # é‡æ–°è·å–ä¸“å®¶å…ƒç´ åˆ—è¡¨ï¼ˆåªæŸ¥æ‰¾å‰8ä¸ªï¼‰
                        experts = driver.find_elements(By.CLASS_NAME, "items")
                        expert_items = experts[:8]
                        target_expert = None

                        # åœ¨å‰8ä¸ªä¸“å®¶ä¸­æŸ¥æ‰¾ç›®æ ‡ä¸“å®¶
                        for expert in expert_items:
                            try:
                                name_element = expert.find_element(By.CLASS_NAME, "okami-name")
                                if name_element.text.strip() == expert_name:
                                    target_expert = name_element
                                    break
                            except:
                                continue

                        if target_expert:
                            # ç‚¹å‡»ä¸“å®¶åç§°è¿›å…¥è¯¦æƒ…é¡µ
                            print(f"ç‚¹å‡»ä¸“å®¶ï¼š{expert_name}")
                            driver.execute_script("arguments[0].click();", target_expert)
                            time.sleep(3)

                            # ç­‰å¾…è¯¦æƒ…é¡µåŠ è½½
                            try:
                                WebDriverWait(driver, 10).until(
                                    EC.presence_of_element_located((By.CLASS_NAME, "okami-text"))
                                )
                                time.sleep(2)
                            except:
                                print(f"ä¸“å®¶è¯¦æƒ…é¡µåŠ è½½è¶…æ—¶ï¼š{expert_name}")
                                # è¿”å›ä¸»é¡µé¢ç»§ç»­
                                driver.get(self.base_url)
                                time.sleep(3)
                                continue

                            # è·å–ä¸“å®¶è¯¦ç»†ä¿¡æ¯
                            expert_data = self.parse_expert_detail(driver)
                            if expert_data:
                                expert_data['name'] = expert_name
                                all_experts.append(expert_data)
                                print(f"æˆåŠŸè·å–ä¸“å®¶ {expert_name} çš„æ•°æ®ï¼Œç›®å‰æ€»æ•°ï¼š{len(all_experts)}")
                            else:
                                print(f"è·å–ä¸“å®¶ {expert_name} æ•°æ®å¤±è´¥")

                            # è¿”å›ä¸»é¡µé¢
                            print("è¿”å›ä¸»é¡µé¢...")
                            driver.get(self.base_url)
                            time.sleep(3)

                            # ç­‰å¾…ä¸»é¡µé¢åŠ è½½å®Œæˆ
                            try:
                                WebDriverWait(driver, 10).until(
                                    EC.presence_of_element_located((By.CLASS_NAME, "items"))
                                )
                                time.sleep(2)
                            except:
                                print("è¿”å›ä¸»é¡µé¢åŠ è½½è¶…æ—¶")
                                break

                        else:
                            print(f"æœªæ‰¾åˆ°ä¸“å®¶ï¼š{expert_name}")

                    except Exception as e:
                        print(f"å¤„ç†ä¸“å®¶ {expert_name} æ—¶å‡ºé”™: {e}")
                        # ç¡®ä¿è¿”å›ä¸»é¡µé¢
                        try:
                            driver.get(self.base_url)
                            time.sleep(3)
                            WebDriverWait(driver, 10).until(
                                EC.presence_of_element_located((By.CLASS_NAME, "items"))
                            )
                            time.sleep(2)
                        except:
                            print("è¿”å›ä¸»é¡µé¢å¤±è´¥")
                            break
                        continue

                rounds += 1

                # å¦‚æœè¿˜éœ€è¦æ›´å¤šä¸“å®¶ï¼Œç‚¹å‡»"æ¢ä¸€æ‰¹"æŒ‰é’®
                if len(all_experts) < target_count and rounds < max_rounds:
                    try:
                        print("å‡†å¤‡ç‚¹å‡»'æ¢ä¸€æ‰¹'æŒ‰é’®...")

                        # ç¡®ä¿åœ¨ä¸»é¡µé¢
                        current_url = driver.current_url
                        if self.base_url not in current_url:
                            driver.get(self.base_url)
                            time.sleep(3)
                            WebDriverWait(driver, 10).until(
                                EC.presence_of_element_located((By.CLASS_NAME, "items"))
                            )
                            time.sleep(2)

                        # æŸ¥æ‰¾å¹¶ç‚¹å‡»"æ¢ä¸€æ‰¹"æŒ‰é’®
                        change_button = WebDriverWait(driver, 10).until(
                            EC.element_to_be_clickable((By.CSS_SELECTOR, "div.change"))
                        )

                        # æ»šåŠ¨åˆ°æŒ‰é’®ä½ç½®
                        driver.execute_script("arguments[0].scrollIntoView(true);", change_button)
                        time.sleep(1)

                        # ç‚¹å‡»æ¢ä¸€æ‰¹æŒ‰é’®
                        driver.execute_script("arguments[0].click();", change_button)
                        print("æˆåŠŸç‚¹å‡»'æ¢ä¸€æ‰¹'æŒ‰é’®")
                        time.sleep(4)  # ç­‰å¾…æ–°çš„ä¸“å®¶åˆ—è¡¨åŠ è½½

                        # éªŒè¯æ–°åˆ—è¡¨æ˜¯å¦åŠ è½½
                        try:
                            WebDriverWait(driver, 10).until(
                                EC.presence_of_element_located((By.CLASS_NAME, "items"))
                            )
                            time.sleep(2)
                            print("æ–°ä¸“å®¶åˆ—è¡¨åŠ è½½å®Œæˆ")
                        except:
                            print("æ–°ä¸“å®¶åˆ—è¡¨åŠ è½½è¶…æ—¶")
                            break

                    except Exception as e:
                        print(f"ç‚¹å‡»'æ¢ä¸€æ‰¹'æŒ‰é’®å¤±è´¥: {e}")
                        # å°è¯•å…¶ä»–æ–¹å¼æŸ¥æ‰¾æŒ‰é’®
                        try:
                            # å°è¯•é€šè¿‡åŒ…å«æ–‡æœ¬"æ¢ä¸€æ‰¹"çš„å…ƒç´ æŸ¥æ‰¾
                            change_buttons = driver.find_elements(By.XPATH, "//div[contains(@class, 'change')]")
                            if change_buttons:
                                driver.execute_script("arguments[0].click();", change_buttons[0])
                                print("é€šè¿‡å¤‡ç”¨æ–¹æ³•ç‚¹å‡»'æ¢ä¸€æ‰¹'æŒ‰é’®")
                                time.sleep(4)
                            else:
                                print("æœªæ‰¾åˆ°'æ¢ä¸€æ‰¹'æŒ‰é’®ï¼Œç»“æŸè·å–")
                                break
                        except Exception as e2:
                            print(f"å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: {e2}")
                            break

            driver.quit()
            print(f"ä¸“å®¶æ•°æ®è·å–å®Œæˆï¼Œå…±è·å–{len(all_experts)}ä½ä¸“å®¶ä¿¡æ¯")
            return all_experts

        except Exception as e:
            print(f"è·å–ä¸“å®¶åˆ—è¡¨æ—¶å‡ºé”™: {e}")
            try:
                driver.quit()
            except:
                pass
            return []

    def parse_expert_detail(self, driver):
        """è§£æä¸“å®¶è¯¦æƒ…é¡µé¢"""
        try:
            # ç­‰å¾…é¡µé¢åŠ è½½
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CLASS_NAME, "okami-text"))
            )
            time.sleep(2)

            expert_data = {}

            # è·å–å½©é¾„
            try:
                cailing_elements = driver.find_elements(By.XPATH, "//p[contains(text(), 'å½©é¾„ï¼š')]/span")
                if cailing_elements:
                    cailing_text = cailing_elements[0].text.strip()
                    cailing_match = re.search(r'(\d+)', cailing_text)
                    expert_data['å½©é¾„'] = int(cailing_match.group(1)) if cailing_match else 1
                else:
                    # å¤‡ç”¨æ–¹æ³•
                    cailing_p = driver.find_elements(By.XPATH, "//p[contains(text(), 'å½©é¾„ï¼š')]")
                    if cailing_p:
                        cailing_text = cailing_p[0].text
                        cailing_match = re.search(r'å½©é¾„ï¼š(\d+)', cailing_text)
                        expert_data['å½©é¾„'] = int(cailing_match.group(1)) if cailing_match else 1
                    else:
                        expert_data['å½©é¾„'] = 1
            except Exception as e:
                print(f"è·å–å½©é¾„æ—¶å‡ºé”™: {e}")
                expert_data['å½©é¾„'] = 1

            # è·å–æ–‡ç« æ•°é‡
            try:
                article_elements = driver.find_elements(By.XPATH, "//p[contains(text(), 'æ–‡ç« æ•°é‡ï¼š')]/span")
                if article_elements:
                    article_text = article_elements[0].text.strip()
                    article_match = re.search(r'(\d+)', article_text)
                    expert_data['æ–‡ç« æ•°é‡'] = int(article_match.group(1)) if article_match else 0
                else:
                    # å¤‡ç”¨æ–¹æ³•
                    article_p = driver.find_elements(By.XPATH, "//p[contains(text(), 'æ–‡ç« æ•°é‡ï¼š')]")
                    if article_p:
                        article_text = article_p[0].text
                        article_match = re.search(r'æ–‡ç« æ•°é‡ï¼š(\d+)', article_text)
                        expert_data['æ–‡ç« æ•°é‡'] = int(article_match.group(1)) if article_match else 0
                    else:
                        expert_data['æ–‡ç« æ•°é‡'] = 0
            except Exception as e:
                print(f"è·å–æ–‡ç« æ•°é‡æ—¶å‡ºé”™: {e}")
                expert_data['æ–‡ç« æ•°é‡'] = 0

            # åˆå§‹åŒ–ä¸­å¥–æƒ…å†µ
            expert_data['å¤§ä¹é€ä¸€ç­‰å¥–'] = 0
            expert_data['å¤§ä¹é€äºŒç­‰å¥–'] = 0
            expert_data['å¤§ä¹é€ä¸‰ç­‰å¥–'] = 0

            # è·å–å¤§ä¹é€ä¸­å¥–æƒ…å†µ
            try:
                # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«å¥–é¡¹ä¿¡æ¯çš„å…ƒç´ 
                prize_elements = driver.find_elements(By.XPATH, "//div[@class='item']")

                for item in prize_elements:
                    try:
                        item_text = item.text
                        # åŒ¹é…å¤§ä¹é€å„ç­‰å¥–
                        if 'å¤§ä¹é€' in item_text and 'ä¸€ç­‰å¥–' in item_text:
                            match = re.search(r'(\d+)', item_text)
                            if match:
                                expert_data['å¤§ä¹é€ä¸€ç­‰å¥–'] = int(match.group(1))
                        elif 'å¤§ä¹é€' in item_text and 'äºŒç­‰å¥–' in item_text:
                            match = re.search(r'(\d+)', item_text)
                            if match:
                                expert_data['å¤§ä¹é€äºŒç­‰å¥–'] = int(match.group(1))
                        elif 'å¤§ä¹é€' in item_text and 'ä¸‰ç­‰å¥–' in item_text:
                            match = re.search(r'(\d+)', item_text)
                            if match:
                                expert_data['å¤§ä¹é€ä¸‰ç­‰å¥–'] = int(match.group(1))
                    except Exception as e:
                        continue

            except Exception as e:
                print(f"è§£æä¸­å¥–æƒ…å†µæ—¶å‡ºé”™: {e}")

            # è·å–ä¸“å®¶ç­‰çº§
            try:
                level_elements = driver.find_elements(By.CLASS_NAME, "expert-rank")
                if level_elements:
                    level_text = level_elements[0].text
                    if 'ç‰¹çº§' in level_text:
                        expert_data['ç­‰çº§'] = 'ç‰¹çº§'
                    elif 'é«˜çº§' in level_text:
                        expert_data['ç­‰çº§'] = 'é«˜çº§'
                    elif 'ä¸­çº§' in level_text:
                        expert_data['ç­‰çº§'] = 'ä¸­çº§'
                    else:
                        expert_data['ç­‰çº§'] = 'åˆçº§'
                else:
                    expert_data['ç­‰çº§'] = 'åˆçº§'
            except Exception as e:
                print(f"è·å–ä¸“å®¶ç­‰çº§æ—¶å‡ºé”™: {e}")
                expert_data['ç­‰çº§'] = 'åˆçº§'

            # è®¡ç®—æ€»ä¸­å¥–æ¬¡æ•°å’Œä¸­å¥–ç‡
            total_wins = expert_data['å¤§ä¹é€ä¸€ç­‰å¥–'] + expert_data['å¤§ä¹é€äºŒç­‰å¥–'] + expert_data['å¤§ä¹é€ä¸‰ç­‰å¥–']
            expert_data['æ€»ä¸­å¥–æ¬¡æ•°'] = total_wins

            # ä¼°ç®—æ¨èæ¬¡æ•°ï¼ˆåŸºäºå½©é¾„å’Œæ–‡ç« æ•°é‡ï¼‰
            estimated_predictions = max(expert_data['å½©é¾„'] * 50, expert_data['æ–‡ç« æ•°é‡'] * 2, 100)
            expert_data['æ¨èæ¬¡æ•°'] = estimated_predictions

            # è®¡ç®—ä¸­å¥–ç‡
            if estimated_predictions > 0:
                expert_data['ä¸­å¥–ç‡'] = (total_wins / estimated_predictions) * 100
            else:
                expert_data['ä¸­å¥–ç‡'] = 0

            print(f"ä¸“å®¶æ•°æ®: å½©é¾„{expert_data['å½©é¾„']}å¹´, æ–‡ç« {expert_data['æ–‡ç« æ•°é‡']}ç¯‡, å¤§ä¹é€ä¸­å¥–{total_wins}æ¬¡")
            return expert_data

        except Exception as e:
            print(f"è§£æä¸“å®¶è¯¦æƒ…æ—¶å‡ºé”™: {e}")
            return None

    def crawl_experts(self, target_count=30):
        """çˆ¬å–ä¸“å®¶æ•°æ®çš„ä¸»æ–¹æ³•"""
        print(f"å¼€å§‹è·å–{target_count}ä½ä¸“å®¶æ•°æ®...")

        experts_data = self.get_expert_list(target_count)

        if experts_data:
            print(f"æˆåŠŸè·å–{len(experts_data)}ä½ä¸“å®¶æ•°æ®")

            # ä¿å­˜ä¸“å®¶æ•°æ®åˆ°æ–‡ä»¶
            try:
                expert_df = pd.DataFrame(experts_data)
                expert_df.to_csv('experts_data.csv', index=False, encoding='utf-8-sig')
                print("ä¸“å®¶æ•°æ®å·²ä¿å­˜åˆ°ï¼šexperts_data.csv")
            except Exception as e:
                print(f"ä¿å­˜ä¸“å®¶æ•°æ®å¤±è´¥ï¼š{e}")
        else:
            print("æœªè·å–åˆ°ä»»ä½•ä¸“å®¶æ•°æ®")

        return experts_data

    def generate_mock_data(self, count=30):
        """ç”Ÿæˆæ¨¡æ‹Ÿä¸“å®¶æ•°æ®ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        expert_names = [
            "å€©å¥³å¹½çƒ", "è¯¸è‘›æˆ˜ç¥", "åˆ˜é£", "ç¦é“ç¼˜", "çº³è´¢çº³ç¦",
            "é‡‘é“ƒé“›", "å¼•é¢†è€…", "æ—¶ä»£å½©æ°‘", "å½©ç¥¨è¾¾äºº", "å¹¸è¿æ˜Ÿ",
            "æ•°å­—ä¸“å®¶", "é¢„æµ‹å¤§å¸ˆ", "ä¸­å¥–ç‹", "å½©ç¥", "è¿åŠ¿åˆ†æå¸ˆ",
            "å·ç çŒæ‰‹", "å½©ç¥¨ç ”ç©¶å‘˜", "å¤§å¥–æ”¶å‰²æœº", "é€‰å·ä¸“å®¶", "æ¦‚ç‡å¤§å¸ˆ",
            "èµ°åŠ¿åˆ†æå¸ˆ", "å½©ç¥¨æ•™æˆ", "ä¸­å¥–ä¸“å®¶", "æ•°æ®åˆ†æå¸ˆ", "å½©ç¥¨é¡¾é—®",
            "é¢„æµ‹ä¸“å®¶", "å½©ç¥¨å¯¼å¸ˆ", "ä¸­å¥–åŠ©æ‰‹", "å·ç ä¸“å®¶", "å½©ç¥¨å­¦è€…"
        ]

        np.random.seed(42)
        mock_experts = []

        for i, name in enumerate(expert_names[:count]):
            expert = {
                'name': name,
                'å½©é¾„': np.random.randint(3, 20),
                'æ–‡ç« æ•°é‡': np.random.randint(100, 2000),
                'å¤§ä¹é€ä¸€ç­‰å¥–': np.random.choice([0, 1, 2, 3, 4, 5], p=[0.3, 0.3, 0.2, 0.1, 0.07, 0.03]),
                'å¤§ä¹é€äºŒç­‰å¥–': np.random.randint(0, 8),
                'å¤§ä¹é€ä¸‰ç­‰å¥–': np.random.randint(2, 20),
                'ç­‰çº§': np.random.choice(['åˆçº§', 'ä¸­çº§', 'é«˜çº§', 'ç‰¹çº§'], p=[0.2, 0.3, 0.4, 0.1])
            }

            # è®¡ç®—æ€»ä¸­å¥–æ¬¡æ•°
            total_wins = expert['å¤§ä¹é€ä¸€ç­‰å¥–'] + expert['å¤§ä¹é€äºŒç­‰å¥–'] + expert['å¤§ä¹é€ä¸‰ç­‰å¥–']
            expert['æ€»ä¸­å¥–æ¬¡æ•°'] = total_wins

            # ä¼°ç®—æ¨èæ¬¡æ•°
            estimated_predictions = max(expert['å½©é¾„'] * 50, expert['æ–‡ç« æ•°é‡'] * 2, 200)
            expert['æ¨èæ¬¡æ•°'] = estimated_predictions

            # è®¡ç®—ä¸­å¥–ç‡
            expert['ä¸­å¥–ç‡'] = (total_wins / estimated_predictions) * 100

            mock_experts.append(expert)

        return mock_experts

if __name__ == "__main__":
    main()