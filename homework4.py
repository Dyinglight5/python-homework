import requests
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import time
import warnings
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import seaborn as sns
from collections import Counter
import random
import re
import json
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
import matplotlib
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans', 'Arial Unicode MS']
matplotlib.rcParams['axes.unicode_minus'] = False
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

class DLTSpider:
    def __init__(self):
        self.base_url = "https://www.zhcw.com/kjxx/dlt/"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        
    def get_page_data(self):
        """è·å–æŒ‡å®šé¡µé¢çš„æ•°æ®"""
        try:
            print("å°è¯•ä»ç½‘ç»œè·å–æ•°æ®...")
            # å¦‚æœç½‘ç»œä¸å¯ç”¨ï¼Œç›´æ¥ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
            with open("wangye.html", "r", encoding='utf-8') as f:
                return [f.read()]
        except FileNotFoundError:
            print("æœ¬åœ°HTMLæ–‡ä»¶ä¸å­˜åœ¨")
            return None

    def parse_lottery_data(self, html_content_list):
        """è§£æå¼€å¥–æ•°æ®"""
        all_data = []

        # å¦‚æœä¼ å…¥çš„æ˜¯å•ä¸ªHTMLå†…å®¹ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
        if isinstance(html_content_list, str):
            html_content_list = [html_content_list]

        for page_num, html_content in enumerate(html_content_list, 1):
            print(f"æ­£åœ¨è§£æç¬¬ {page_num} é¡µæ•°æ®...")

            soup = BeautifulSoup(html_content, 'html.parser')

            # æŸ¥æ‰¾åŒ…å«å¼€å¥–æ•°æ®çš„è¡¨æ ¼
            table = soup.find('table')

            if not table:
                print(f"ç¬¬ {page_num} é¡µæœªæ‰¾åˆ°æ•°æ®è¡¨æ ¼")
                continue

            # æŸ¥æ‰¾è¡¨æ ¼çš„tbodyéƒ¨åˆ†
            tbody = table.find('tbody')
            if not tbody:
                print(f"ç¬¬ {page_num} é¡µæœªæ‰¾åˆ°è¡¨æ ¼æ•°æ®")
                continue

            # è§£ææ¯ä¸€è¡Œæ•°æ®
            rows = tbody.find_all('tr')

            for row in rows:
                try:
                    cells = row.find_all('td')
                    if len(cells) < 14:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„åˆ—
                        continue

                    # æå–æœŸå·
                    period = cells[0].get_text(strip=True)

                    # æå–å¼€å¥–æ—¥æœŸ
                    date_text = cells[1].get_text(strip=True)
                    # æå–æ—¥æœŸéƒ¨åˆ†ï¼Œå»æ‰æ˜ŸæœŸä¿¡æ¯
                    date_match = date_text.split('ï¼ˆ')[0] if 'ï¼ˆ' in date_text else date_text

                    # æå–å‰åŒºå·ç 
                    front_numbers = []
                    front_spans = cells[2].find_all('span', class_='jqh')
                    for span in front_spans:
                        front_numbers.append(span.get_text(strip=True))

                    # æå–ååŒºå·ç 
                    back_numbers = []
                    back_spans = cells[3].find_all('span', class_='jql')
                    for span in back_spans:
                        back_numbers.append(span.get_text(strip=True))

                    # æå–é”€å”®é¢
                    sales_amount = cells[4].get_text(strip=True)

                    # æå–ä¸€ç­‰å¥–ä¿¡æ¯
                    first_prize_count = cells[5].get_text(strip=True)
                    first_prize_amount = cells[6].get_text(strip=True)
                    first_prize_plus_count = cells[7].get_text(strip=True)
                    first_prize_plus_amount = cells[8].get_text(strip=True)

                    # æå–äºŒç­‰å¥–ä¿¡æ¯
                    second_prize_count = cells[9].get_text(strip=True)
                    second_prize_amount = cells[10].get_text(strip=True)
                    second_prize_plus_count = cells[11].get_text(strip=True)
                    second_prize_plus_amount = cells[12].get_text(strip=True)

                    # æå–å¥–æ± é‡‘é¢
                    prize_pool = cells[13].get_text(strip=True)

                    # ç»„è£…æ•°æ®
                    lottery_data = {
                        'æœŸå·': period,
                        'å¼€å¥–æ—¥æœŸ': date_match,
                        'å‰åŒºå·ç ': ' '.join(front_numbers),
                        'ååŒºå·ç ': ' '.join(back_numbers),
                        'é”€å”®é¢': sales_amount,
                        'ä¸€ç­‰å¥–æ³¨æ•°': first_prize_count,
                        'ä¸€ç­‰å¥–å•æ³¨å¥–é‡‘': first_prize_amount,
                        'ä¸€ç­‰å¥–è¿½åŠ æ³¨æ•°': first_prize_plus_count,
                        'ä¸€ç­‰å¥–è¿½åŠ å•æ³¨å¥–é‡‘': first_prize_plus_amount,
                        'äºŒç­‰å¥–æ³¨æ•°': second_prize_count,
                        'äºŒç­‰å¥–å•æ³¨å¥–é‡‘': second_prize_amount,
                        'äºŒç­‰å¥–è¿½åŠ æ³¨æ•°': second_prize_plus_count,
                        'äºŒç­‰å¥–è¿½åŠ å•æ³¨å¥–é‡‘': second_prize_plus_amount,
                        'å¥–æ± é‡‘é¢': prize_pool
                    }

                    all_data.append(lottery_data)

                except Exception as e:
                    print(f"è§£æè¡Œæ•°æ®æ—¶å‡ºé”™: {e}")
                    continue

            print(f"ç¬¬ {page_num} é¡µè§£æå®Œæˆï¼Œè·å¾— {len(rows)} æ¡æ•°æ®")

        # æŒ‰æœŸå·æ’åºï¼Œç¡®ä¿æ•°æ®é¡ºåºæ­£ç¡®
        if all_data:
            all_data.sort(key=lambda x: int(x['æœŸå·']), reverse=True)

        return all_data

    def crawl_lottery_data(self, target_periods=100):
        """çˆ¬å–æŒ‡å®šæœŸæ•°çš„å¼€å¥–æ•°æ®"""
        print("å¼€å§‹è·å–å¤§ä¹é€å¼€å¥–æ•°æ®...")

        # è·å–HTMLå†…å®¹
        html_content_list = self.get_page_data()

        if not html_content_list:
            print("æœªèƒ½è·å–åˆ°æ•°æ®")
            return []

        # è§£ææ‰€æœ‰é¡µé¢çš„æ•°æ®
        all_data = self.parse_lottery_data(html_content_list)

        if not all_data:
            print("æœªèƒ½è§£æåˆ°å¼€å¥–æ•°æ®")
            return []

        print(f"æ€»å…±è§£æåˆ° {len(all_data)} æ¡å¼€å¥–æ•°æ®")

        # è¿‡æ»¤2025å¹´7æœˆ1æ—¥ä¹‹å‰çš„æ•°æ®
        cutoff_date = datetime(2025, 7, 1)
        filtered_data = []

        for data in all_data:
            try:
                # è§£ææ—¥æœŸ
                date_obj = datetime.strptime(data['å¼€å¥–æ—¥æœŸ'], '%Y-%m-%d')
                if date_obj < cutoff_date:
                    filtered_data.append(data)
            except Exception as e:
                print(f"æ—¥æœŸè§£æé”™è¯¯: {data['å¼€å¥–æ—¥æœŸ']} - {e}")
                continue

        print(f"è¿‡æ»¤åè·å¾— {len(filtered_data)} æ¡2025å¹´7æœˆ1æ—¥ä¹‹å‰çš„æ•°æ®")

        # å¦‚æœéœ€è¦é™åˆ¶æœŸæ•°ï¼Œå–æœ€æ–°çš„target_periodsæœŸ
        if len(filtered_data) > target_periods:
            filtered_data = filtered_data[:target_periods]
            print(f"æŒ‰éœ€æ±‚é™åˆ¶ä¸ºæœ€æ–° {target_periods} æœŸæ•°æ®")

        return filtered_data

class DLTAnalyzer:
    def __init__(self, data):
        self.df = pd.DataFrame(data)
        self.prepare_data()
    
    def prepare_data(self):
        """æ•°æ®é¢„å¤„ç†"""
        if self.df.empty:
            print("æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
            return
        
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        self.df['å¼€å¥–æ—¥æœŸ'] = pd.to_datetime(self.df['å¼€å¥–æ—¥æœŸ'], errors='coerce')
        
        # æ¸…ç†é”€å”®é¢æ•°æ®
        self.df['é”€å”®é¢'] = self.df['é”€å”®é¢'].astype(str).str.replace(',', '').str.replace('å…ƒ', '')
        self.df['é”€å”®é¢'] = pd.to_numeric(self.df['é”€å”®é¢'], errors='coerce').fillna(0)
        
        # æŒ‰æ—¥æœŸæ’åº
        self.df = self.df.sort_values('å¼€å¥–æ—¥æœŸ').reset_index(drop=True)
        
        # è¿‡æ»¤æ‰2025å¹´7æœˆ1æ—¥ä¹‹åçš„æ•°æ®
        cutoff_date = datetime(2025, 7, 1)
        self.df = self.df[self.df['å¼€å¥–æ—¥æœŸ'] < cutoff_date]
        
        # æ·»åŠ æ˜ŸæœŸå‡ åˆ—
        self.df['æ˜ŸæœŸå‡ '] = self.df['å¼€å¥–æ—¥æœŸ'].dt.day_name()
        self.df['ä¸­æ–‡æ˜ŸæœŸ'] = self.df['å¼€å¥–æ—¥æœŸ'].dt.dayofweek.map({
            0: 'å‘¨ä¸€', 1: 'å‘¨äºŒ', 2: 'å‘¨ä¸‰', 3: 'å‘¨å››', 4: 'å‘¨äº”', 5: 'å‘¨å…­', 6: 'å‘¨æ—¥'
        })

        print(f"æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œå…±{len(self.df)}æ¡æœ‰æ•ˆæ•°æ®")
        print(f"æ—¥æœŸèŒƒå›´ï¼š{self.df['å¼€å¥–æ—¥æœŸ'].min()} åˆ° {self.df['å¼€å¥–æ—¥æœŸ'].max()}")
    
    def analyze_sales_trend(self):
        """åˆ†æé”€å”®é¢å˜åŒ–è¶‹åŠ¿å¹¶é¢„æµ‹"""
        if self.df.empty or self.df['é”€å”®é¢'].sum() == 0:
            print("é”€å”®é¢æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œè¶‹åŠ¿åˆ†æ")
            return
        
        # åˆ›å»ºå›¾è¡¨
        plt.figure(figsize=(15, 10))
        
        # å­å›¾1ï¼šé”€å”®é¢æ—¶é—´åºåˆ—
        plt.subplot(2, 2, 1)
        plt.plot(self.df['å¼€å¥–æ—¥æœŸ'], self.df['é”€å”®é¢'], marker='o', markersize=3, linewidth=1)
        plt.title('å¤§ä¹é€é”€å”®é¢å˜åŒ–è¶‹åŠ¿')
        plt.xlabel('å¼€å¥–æ—¥æœŸ')
        plt.ylabel('é”€å”®é¢ï¼ˆå…ƒï¼‰')
        plt.xticks(rotation=45)
        plt.grid(True, alpha=0.3)
        
        # å­å›¾2ï¼šé”€å”®é¢åˆ†å¸ƒç›´æ–¹å›¾
        plt.subplot(2, 2, 2)
        plt.hist(self.df['é”€å”®é¢'], bins=20, alpha=0.7, edgecolor='black')
        plt.title('é”€å”®é¢åˆ†å¸ƒ')
        plt.xlabel('é”€å”®é¢ï¼ˆå…ƒï¼‰')
        plt.ylabel('é¢‘æ¬¡')
        plt.grid(True, alpha=0.3)
        
        # å­å›¾3ï¼šç§»åŠ¨å¹³å‡çº¿
        plt.subplot(2, 2, 3)
        window = min(10, len(self.df) // 4)
        if window >= 2:
            moving_avg = self.df['é”€å”®é¢'].rolling(window=window).mean()
            plt.plot(self.df['å¼€å¥–æ—¥æœŸ'], self.df['é”€å”®é¢'], alpha=0.5, label='åŸå§‹æ•°æ®')
            plt.plot(self.df['å¼€å¥–æ—¥æœŸ'], moving_avg, color='red', linewidth=2, label=f'{window}æœŸç§»åŠ¨å¹³å‡')
            plt.title('é”€å”®é¢ç§»åŠ¨å¹³å‡çº¿')
            plt.xlabel('å¼€å¥–æ—¥æœŸ')
            plt.ylabel('é”€å”®é¢ï¼ˆå…ƒï¼‰')
            plt.legend()
            plt.xticks(rotation=45)
            plt.grid(True, alpha=0.3)
        
        # å­å›¾4ï¼šé¢„æµ‹ç»“æœ
        plt.subplot(2, 2, 4)
        recent_data = self.df['é”€å”®é¢'].tail(10)
        predicted_sales = recent_data.mean()

        plt.plot(range(len(recent_data)), recent_data, 'b-o', markersize=5, label='æœ€è¿‘10æœŸé”€å”®é¢')
        plt.axhline(y=predicted_sales, color='red', linestyle='--', label=f'é¢„æµ‹é”€å”®é¢: {predicted_sales:.0f}å…ƒ')
        plt.title('é”€å”®é¢é¢„æµ‹')
        plt.xlabel('æœŸæ•°')
        plt.ylabel('é”€å”®é¢ï¼ˆå…ƒï¼‰')
        plt.legend()
        plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.show()
        
        # æ‰“å°è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        print("\n=== é”€å”®é¢ç»Ÿè®¡åˆ†æ ===")
        print(f"æ•°æ®æœŸé—´ï¼š{self.df['å¼€å¥–æ—¥æœŸ'].min().strftime('%Y-%m-%d')} è‡³ {self.df['å¼€å¥–æ—¥æœŸ'].max().strftime('%Y-%m-%d')}")
        print(f"æ€»æœŸæ•°ï¼š{len(self.df)}æœŸ")
        print(f"å¹³å‡é”€å”®é¢ï¼š{self.df['é”€å”®é¢'].mean():.2f}å…ƒ")
        print(f"é”€å”®é¢ä¸­ä½æ•°ï¼š{self.df['é”€å”®é¢'].median():.2f}å…ƒ")
        print(f"æœ€é«˜é”€å”®é¢ï¼š{self.df['é”€å”®é¢'].max():.2f}å…ƒ")
        print(f"æœ€ä½é”€å”®é¢ï¼š{self.df['é”€å”®é¢'].min():.2f}å…ƒ")
        print(f"æ ‡å‡†å·®ï¼š{self.df['é”€å”®é¢'].std():.2f}å…ƒ")
        print(f"\né¢„æµ‹2025å¹´7æœˆ1æ—¥åæœ€è¿‘ä¸€æœŸé”€å”®é¢ï¼š{predicted_sales:.0f}å…ƒ")

        return predicted_sales

    def analyze_number_frequency(self, top_n=10):
        """åˆ†æå·ç å‡ºç°é¢‘ç‡"""
        if self.df.empty:
            print("æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œå·ç é¢‘ç‡åˆ†æ")
            return

        # æå–æ‰€æœ‰å‰åŒºå’ŒååŒºå·ç 
        all_front_numbers = []
        all_back_numbers = []

        for _, row in self.df.iterrows():
            front_numbers = row['å‰åŒºå·ç '].split()
            back_numbers = row['ååŒºå·ç '].split()

            all_front_numbers.extend([int(num) for num in front_numbers])
            all_back_numbers.extend([int(num) for num in back_numbers])

        # è®¡ç®—å·ç é¢‘ç‡
        front_number_freq = Counter(all_front_numbers)
        back_number_freq = Counter(all_back_numbers)

        # åˆ›å»ºå®Œæ•´çš„å‰åŒºå’ŒååŒºå·ç é¢‘ç‡ç»Ÿè®¡
        front_freq_complete = {i: front_number_freq.get(i, 0) for i in range(1, 36)}
        back_freq_complete = {i: back_number_freq.get(i, 0) for i in range(1, 13)}

        # åˆ›å»ºå¯è§†åŒ–
        plt.figure(figsize=(20, 12))

        # å‰åŒºå·ç é¢‘ç‡çƒ­åŠ›å›¾
        plt.subplot(2, 2, 1)
        front_matrix = np.array(list(front_freq_complete.values())).reshape(7, 5)
        front_labels = np.array(list(front_freq_complete.keys())).reshape(7, 5)

        sns.heatmap(front_matrix, annot=front_labels, fmt='d', cmap='YlOrRd',
                   cbar_kws={'label': 'å‡ºç°æ¬¡æ•°'})
        plt.title('å‰åŒºå·ç å‡ºç°é¢‘ç‡çƒ­åŠ›å›¾ï¼ˆ1-35ï¼‰')

        # ååŒºå·ç é¢‘ç‡çƒ­åŠ›å›¾
        plt.subplot(2, 2, 2)
        back_matrix = np.array(list(back_freq_complete.values())).reshape(3, 4)
        back_labels = np.array(list(back_freq_complete.keys())).reshape(3, 4)

        sns.heatmap(back_matrix, annot=back_labels, fmt='d', cmap='YlOrRd',
                   cbar_kws={'label': 'å‡ºç°æ¬¡æ•°'})
        plt.title('ååŒºå·ç å‡ºç°é¢‘ç‡çƒ­åŠ›å›¾ï¼ˆ1-12ï¼‰')

        # å‰åŒºTopå·ç æŸ±çŠ¶å›¾
        plt.subplot(2, 2, 3)
        common_front = front_number_freq.most_common(top_n)
        front_numbers, front_counts = zip(*common_front)
        plt.bar([str(num) for num in front_numbers], front_counts, color='skyblue')
        plt.title(f'å‰åŒºå·ç å‡ºç°é¢‘ç‡Top {top_n}')
        plt.xlabel('å·ç ')
        plt.ylabel('å‡ºç°æ¬¡æ•°')
        plt.grid(axis='y', alpha=0.3)

        # ååŒºTopå·ç æŸ±çŠ¶å›¾
        plt.subplot(2, 2, 4)
        common_back = back_number_freq.most_common(top_n)
        back_numbers, back_counts = zip(*common_back)
        plt.bar([str(num) for num in back_numbers], back_counts, color='lightcoral')
        plt.title(f'ååŒºå·ç å‡ºç°é¢‘ç‡Top {top_n}')
        plt.xlabel('å·ç ')
        plt.ylabel('å‡ºç°æ¬¡æ•°')
        plt.grid(axis='y', alpha=0.3)

        plt.tight_layout()
        plt.show()

        # åˆ†æçƒ­å·å’Œå†·å·
        print(f"\n=== å·ç å‡ºç°é¢‘ç‡åˆ†æ ===")
        print(f"åˆ†ææœŸæ•°ï¼š{len(self.df)}æœŸ")

        # å‰åŒºçƒ­å·å’Œå†·å·
        front_hot_numbers = [num for num, _ in front_number_freq.most_common(10)]
        front_cold_numbers = [num for num in range(1, 36) if front_number_freq.get(num, 0) <= 2]

        print(f"\nå‰åŒºçƒ­å·ï¼ˆTop 10ï¼‰ï¼š{', '.join(map(str, front_hot_numbers))}")
        print(f"å‰åŒºå†·å·ï¼ˆå‡ºç°â‰¤2æ¬¡ï¼‰ï¼š{', '.join(map(str, sorted(front_cold_numbers)))}")

        # ååŒºçƒ­å·å’Œå†·å·
        back_hot_numbers = [num for num, _ in back_number_freq.most_common(6)]
        back_cold_numbers = [num for num in range(1, 13) if back_number_freq.get(num, 0) <= 1]

        print(f"\nååŒºçƒ­å·ï¼ˆTop 6ï¼‰ï¼š{', '.join(map(str, back_hot_numbers))}")
        print(f"ååŒºå†·å·ï¼ˆå‡ºç°â‰¤1æ¬¡ï¼‰ï¼š{', '.join(map(str, sorted(back_cold_numbers)))}")

        return front_number_freq, back_number_freq

    def predict_lottery_numbers(self):
        """é¢„æµ‹å¤§ä¹é€å·ç """
        if self.df.empty:
            print("æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œå·ç é¢„æµ‹")
            return None, None

        print("\n=== æ™ºèƒ½å·ç é¢„æµ‹ ===")

        # è·å–å†å²é¢‘ç‡
        front_freq, back_freq = self.analyze_number_frequency(top_n=15)

        # æœ€è¿‘20æœŸè¶‹åŠ¿åˆ†æ
        recent_df = self.df.tail(20)
        recent_front_numbers = []
        recent_back_numbers = []

        for _, row in recent_df.iterrows():
            front_numbers = row['å‰åŒºå·ç '].split()
            back_numbers = row['ååŒºå·ç '].split()
            recent_front_numbers.extend([int(num) for num in front_numbers])
            recent_back_numbers.extend([int(num) for num in back_numbers])

        recent_front_freq = Counter(recent_front_numbers)
        recent_back_freq = Counter(recent_back_numbers)

        # ç»¼åˆè¯„åˆ†ç®—æ³•
        def calculate_score(num, all_freq, recent_freq, is_front=True):
            max_num = 35 if is_front else 12

            # å†å²é¢‘ç‡æƒé‡ (40%)
            total_appearances = sum(all_freq.values())
            historical_score = (all_freq.get(num, 0) / total_appearances) * 40 if total_appearances > 0 else 0

            # æœ€è¿‘è¶‹åŠ¿æƒé‡ (30%)
            recent_total = sum(recent_freq.values())
            recent_score = (recent_freq.get(num, 0) / recent_total) * 30 if recent_total > 0 else 0

            # å¹³è¡¡æ€§æƒé‡ (20%)
            avg_freq = total_appearances / max_num if total_appearances > 0 else 0
            current_freq = all_freq.get(num, 0)
            balance_score = 20 - abs(current_freq - avg_freq) * 2
            balance_score = max(0, balance_score)

            # éšæœºå› å­ (10%)
            random_score = random.uniform(0, 10)

            return historical_score + recent_score + balance_score + random_score

        # è®¡ç®—å‰åŒºå·ç å¾—åˆ†
        front_scores = {}
        for num in range(1, 36):
            score = calculate_score(num, front_freq, recent_front_freq, True)
            front_scores[num] = score

        # è®¡ç®—ååŒºå·ç å¾—åˆ†
        back_scores = {}
        for num in range(1, 13):
            score = calculate_score(num, back_freq, recent_back_freq, False)
            back_scores[num] = score

        # é€‰æ‹©å‰åŒºå·ç ï¼ˆç¡®ä¿å¥‡å¶å’Œå¤§å°å·å¹³è¡¡ï¼‰
        sorted_front = sorted(front_scores.items(), key=lambda x: x[1], reverse=True)

        predicted_front = []
        odd_count = 0
        even_count = 0
        small_count = 0
        big_count = 0

        for num, score in sorted_front:
            if len(predicted_front) >= 5:
                break

            is_odd = num % 2 == 1
            is_small = num <= 17

            # æ§åˆ¶å¥‡å¶æ¯”ä¾‹ï¼ˆå»ºè®®2-3ä¸ªå¥‡æ•°ï¼‰
            if is_odd and odd_count >= 3:
                continue
            if not is_odd and even_count >= 3:
                continue

            # æ§åˆ¶å¤§å°å·æ¯”ä¾‹ï¼ˆå»ºè®®2-3ä¸ªå°å·ï¼‰
            if is_small and small_count >= 3:
                continue
            if not is_small and big_count >= 3:
                continue

            predicted_front.append(num)
            if is_odd:
                odd_count += 1
            else:
                even_count += 1
            if is_small:
                small_count += 1
            else:
                big_count += 1

        # å¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„å·ç ï¼Œè¡¥å……æœ€é«˜åˆ†çš„å·ç 
        if len(predicted_front) < 5:
            for num, score in sorted_front:
                if num not in predicted_front:
                    predicted_front.append(num)
                    if len(predicted_front) >= 5:
                        break

        # é€‰æ‹©ååŒºå·ç 
        sorted_back = sorted(back_scores.items(), key=lambda x: x[1], reverse=True)
        predicted_back = [num for num, score in sorted_back[:2]]

        # æ ¼å¼åŒ–è¾“å‡º
        predicted_front_str = [f"{num:02d}" for num in sorted(predicted_front)]
        predicted_back_str = [f"{num:02d}" for num in sorted(predicted_back)]

        print("æ¨èå·ç ç»„åˆï¼š")
        print(f"å‰åŒºï¼š{' '.join(predicted_front_str)}")
        print(f"ååŒºï¼š{' '.join(predicted_back_str)}")

        # åˆ†ææ¨èå·ç çš„ç‰¹å¾
        odd_count = sum(1 for num in predicted_front if num % 2 == 1)
        small_count = sum(1 for num in predicted_front if num <= 17)

        print(f"\nå·ç ç‰¹å¾åˆ†æï¼š")
        print(f"å¥‡å¶æ¯”ä¾‹ï¼š{odd_count}å¥‡{5-odd_count}å¶")
        print(f"å¤§å°æ¯”ä¾‹ï¼š{small_count}å°{5-small_count}å¤§")

        # ç”Ÿæˆå¤šç»„å¤‡é€‰å·ç 
        print(f"\n=== å¤‡é€‰å·ç ç»„åˆ ===")
        for i in range(3):
            # åŸºäºæ™ºèƒ½é¢„æµ‹ç”Ÿæˆå¤‡é€‰ç»„åˆ
            backup_front = random.sample([num for num, _ in sorted_front[:15]], 5)
            backup_back = random.sample([num for num, _ in sorted_back[:8]], 2)

            front_str = [f"{num:02d}" for num in sorted(backup_front)]
            back_str = [f"{num:02d}" for num in sorted(backup_back)]

            print(f"å¤‡é€‰{i+1}ï¼šå‰åŒº {' '.join(front_str)} | ååŒº {' '.join(back_str)}")

        return predicted_front, predicted_back

    def analyze_weekday_patterns(self):
        """åˆ†æä¸åŒå¼€å¥–æ—¥çš„å·ç åˆ†å¸ƒå’Œé”€å”®é¢ç‰¹å¾"""
        if self.df.empty:
            print("æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ†æ")
            return

        print("\n=== ä¸åŒå¼€å¥–æ—¥åˆ†æ ===")

        # ç­›é€‰å‘¨ä¸€ã€å‘¨ä¸‰ã€å‘¨å…­çš„æ•°æ®
        target_days = ['å‘¨ä¸€', 'å‘¨ä¸‰', 'å‘¨å…­']
        weekday_data = {}

        for day in target_days:
            day_df = self.df[self.df['ä¸­æ–‡æ˜ŸæœŸ'] == day]
            if not day_df.empty:
                weekday_data[day] = day_df

        if not weekday_data:
            print("æ²¡æœ‰æ‰¾åˆ°å‘¨ä¸€ã€å‘¨ä¸‰ã€å‘¨å…­çš„å¼€å¥–æ•°æ®")
            return

        # åˆ›å»ºå¯è§†åŒ–
        plt.figure(figsize=(20, 12))

        # é”€å”®é¢å¯¹æ¯”
        plt.subplot(2, 3, 1)
        sales_by_day = []
        day_labels = []
        for day, data in weekday_data.items():
            sales_by_day.append(data['é”€å”®é¢'].tolist())
            day_labels.append(f"{day}({len(data)}æœŸ)")

        plt.boxplot(sales_by_day, labels=day_labels)
        plt.title('ä¸åŒå¼€å¥–æ—¥é”€å”®é¢åˆ†å¸ƒå¯¹æ¯”')
        plt.ylabel('é”€å”®é¢ï¼ˆå…ƒï¼‰')
        plt.xticks(rotation=45)
        plt.grid(True, alpha=0.3)

        # å‰åŒºå·ç é¢‘ç‡å¯¹æ¯”
        plt.subplot(2, 3, 2)
        front_freq_by_day = {}
        for day, data in weekday_data.items():
            all_front = []
            for _, row in data.iterrows():
                front_numbers = row['å‰åŒºå·ç '].split()
                all_front.extend([int(num) for num in front_numbers])
            front_freq_by_day[day] = Counter(all_front)

        # è®¡ç®—æ¯ä¸ªå·ç åœ¨ä¸åŒæ—¥æœŸçš„å‡ºç°é¢‘ç‡
        all_front_numbers = list(range(1, 36))
        freq_matrix = []
        for num in all_front_numbers[:15]:  # åªæ˜¾ç¤ºå‰15ä¸ªå·ç 
            freq_row = []
            for day in target_days:
                if day in front_freq_by_day:
                    freq_row.append(front_freq_by_day[day].get(num, 0))
                else:
                    freq_row.append(0)
            freq_matrix.append(freq_row)

        freq_matrix = np.array(freq_matrix)
        sns.heatmap(freq_matrix,
                   xticklabels=[f"{day}({len(weekday_data.get(day, []))}æœŸ)" for day in target_days],
                   yticklabels=[f"{num:02d}" for num in all_front_numbers[:15]],
                   annot=True, fmt='d', cmap='Blues')
        plt.title('å‰åŒºå·ç é¢‘ç‡å¯¹æ¯”ï¼ˆå‰15ä¸ªå·ç ï¼‰')

        # ååŒºå·ç é¢‘ç‡å¯¹æ¯”
        plt.subplot(2, 3, 3)
        back_freq_by_day = {}
        for day, data in weekday_data.items():
            all_back = []
            for _, row in data.iterrows():
                back_numbers = row['ååŒºå·ç '].split()
                all_back.extend([int(num) for num in back_numbers])
            back_freq_by_day[day] = Counter(all_back)

        # è®¡ç®—ååŒºå·ç é¢‘ç‡çŸ©é˜µ
        all_back_numbers = list(range(1, 13))
        back_freq_matrix = []
        for num in all_back_numbers:
            freq_row = []
            for day in target_days:
                if day in back_freq_by_day:
                    freq_row.append(back_freq_by_day[day].get(num, 0))
                else:
                    freq_row.append(0)
            back_freq_matrix.append(freq_row)

        back_freq_matrix = np.array(back_freq_matrix)
        sns.heatmap(back_freq_matrix,
                   xticklabels=[f"{day}({len(weekday_data.get(day, []))}æœŸ)" for day in target_days],
                   yticklabels=[f"{num:02d}" for num in all_back_numbers],
                   annot=True, fmt='d', cmap='Reds')
        plt.title('ååŒºå·ç é¢‘ç‡å¯¹æ¯”')

        # å¥‡å¶æ¯”ä¾‹åˆ†æ
        plt.subplot(2, 3, 4)
        odd_even_patterns = {}
        for day, data in weekday_data.items():
            patterns = []
            for _, row in data.iterrows():
                front_numbers = [int(num) for num in row['å‰åŒºå·ç '].split()]
                odd_count = sum(1 for num in front_numbers if num % 2 == 1)
                patterns.append(f"{odd_count}å¥‡{5-odd_count}å¶")
            odd_even_patterns[day] = Counter(patterns)

        # ç»˜åˆ¶å¥‡å¶æ¯”ä¾‹åˆ†å¸ƒ
        pattern_types = ['1å¥‡4å¶', '2å¥‡3å¶', '3å¥‡2å¶', '4å¥‡1å¶', '5å¥‡0å¶']
        x_pos = np.arange(len(pattern_types))
        bar_width = 0.25

        for i, (day, patterns) in enumerate(odd_even_patterns.items()):
            counts = [patterns.get(pattern, 0) for pattern in pattern_types]
            plt.bar(x_pos + i * bar_width, counts, bar_width, label=day)

        plt.xlabel('å¥‡å¶æ¯”ä¾‹')
        plt.ylabel('å‡ºç°æ¬¡æ•°')
        plt.title('ä¸åŒå¼€å¥–æ—¥å¥‡å¶æ¯”ä¾‹åˆ†å¸ƒ')
        plt.xticks(x_pos + bar_width, pattern_types, rotation=45)
        plt.legend()
        plt.grid(axis='y', alpha=0.3)

        # å¤§å°å·æ¯”ä¾‹åˆ†æ
        plt.subplot(2, 3, 5)
        size_patterns = {}
        for day, data in weekday_data.items():
            patterns = []
            for _, row in data.iterrows():
                front_numbers = [int(num) for num in row['å‰åŒºå·ç '].split()]
                small_count = sum(1 for num in front_numbers if num <= 17)
                patterns.append(f"{small_count}å°{5-small_count}å¤§")
            size_patterns[day] = Counter(patterns)

        # ç»˜åˆ¶å¤§å°å·æ¯”ä¾‹åˆ†å¸ƒ
        size_types = ['1å°4å¤§', '2å°3å¤§', '3å°2å¤§', '4å°1å¤§', '5å°0å¤§']
        x_pos = np.arange(len(size_types))

        for i, (day, patterns) in enumerate(size_patterns.items()):
            counts = [patterns.get(pattern, 0) for pattern in size_types]
            plt.bar(x_pos + i * bar_width, counts, bar_width, label=day)

        plt.xlabel('å¤§å°å·æ¯”ä¾‹')
        plt.ylabel('å‡ºç°æ¬¡æ•°')
        plt.title('ä¸åŒå¼€å¥–æ—¥å¤§å°å·æ¯”ä¾‹åˆ†å¸ƒ')
        plt.xticks(x_pos + bar_width, size_types, rotation=45)
        plt.legend()
        plt.grid(axis='y', alpha=0.3)

        # ç»Ÿè®¡ä¿¡æ¯å¯¹æ¯”
        plt.subplot(2, 3, 6)
        stats_text = ""
        for day, data in weekday_data.items():
            avg_sales = data['é”€å”®é¢'].mean()
            period_count = len(data)
            stats_text += f"{day}å¼€å¥–ç»Ÿè®¡ï¼š\n"
            stats_text += f"  æœŸæ•°ï¼š{period_count}æœŸ\n"
            stats_text += f"  å¹³å‡é”€å”®é¢ï¼š{avg_sales:.0f}å…ƒ\n\n"

        plt.text(0.1, 0.5, stats_text, fontsize=12, verticalalignment='center')
        plt.axis('off')
        plt.title('ç»Ÿè®¡ä¿¡æ¯å¯¹æ¯”')

        plt.tight_layout()
        plt.show()

        # æ‰“å°è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        print("=== ä¸åŒå¼€å¥–æ—¥ç»Ÿè®¡å¯¹æ¯” ===")
        for day, data in weekday_data.items():
            print(f"\n{day}å¼€å¥–ï¼ˆ{len(data)}æœŸï¼‰ï¼š")
            print(f"  å¹³å‡é”€å”®é¢ï¼š{data['é”€å”®é¢'].mean():.2f}å…ƒ")
            print(f"  é”€å”®é¢æ ‡å‡†å·®ï¼š{data['é”€å”®é¢'].std():.2f}å…ƒ")

            # å‰åŒºçƒ­é—¨å·ç 
            all_front = []
            for _, row in data.iterrows():
                front_numbers = row['å‰åŒºå·ç '].split()
                all_front.extend([int(num) for num in front_numbers])
            front_freq = Counter(all_front)
            hot_front = [str(num) for num, _ in front_freq.most_common(5)]
            print(f"  å‰åŒºçƒ­é—¨å·ç ï¼š{', '.join(hot_front)}")

            # ååŒºçƒ­é—¨å·ç 
            all_back = []
            for _, row in data.iterrows():
                back_numbers = row['ååŒºå·ç '].split()
                all_back.extend([int(num) for num in back_numbers])
            back_freq = Counter(all_back)
            hot_back = [str(num) for num, _ in back_freq.most_common(3)]
            print(f"  ååŒºçƒ­é—¨å·ç ï¼š{', '.join(hot_back)}")


    def save_data(self, filename='dlt_data.csv'):
        """ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶"""
        try:
            self.df.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f"æ•°æ®å·²ä¿å­˜åˆ°ï¼š{filename}")
        except Exception as e:
            print(f"ä¿å­˜æ•°æ®å¤±è´¥ï¼š{e}")

def show_menu():
    """æ˜¾ç¤ºèœå•"""
    print("\n" + "="*60)
    print("               å¤§ä¹é€æ•°æ®åˆ†æç³»ç»Ÿ")
    print("="*60)
    print("è¯·é€‰æ‹©åŠŸèƒ½ï¼š")
    print("1. é”€å”®é¢è¶‹åŠ¿åˆ†æä¸é¢„æµ‹")
    print("2. å·ç é¢‘ç‡ç»Ÿè®¡ä¸å¯è§†åŒ–åˆ†æ")
    print("3. æ™ºèƒ½å·ç é¢„æµ‹æ¨è")
    print("4. ä¸åŒå¼€å¥–æ—¥å¯¹æ¯”åˆ†æ")
    print("5. ä¸“å®¶æ•°æ®ç»Ÿè®¡åˆ†æ")
    print("6. ç»¼åˆåˆ†ææŠ¥å‘Š")
    print("0. é€€å‡ºç³»ç»Ÿ")
    print("="*60)

def main():
    """ä¸»å‡½æ•°"""
    print("=== å¤§ä¹é€æ•°æ®åˆ†æç³»ç»Ÿå¯åŠ¨ ===")

    # åŠ è½½æ•°æ®
    try:
        print("æ­£åœ¨åŠ è½½æ•°æ®...")
        # ä¼˜å…ˆä»CSVæ–‡ä»¶åŠ è½½
        try:
            df_existing = pd.read_csv('å¤§ä¹é€å¼€å¥–æ•°æ®.csv', encoding='utf-8-sig')
            if not df_existing.empty:
                print(f"ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®æˆåŠŸï¼Œå…±{len(df_existing)}æ¡è®°å½•")
                lottery_data = df_existing.to_dict('records')
            else:
                raise FileNotFoundError("CSVæ–‡ä»¶ä¸ºç©º")
        except:
            # å¦‚æœCSVæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œä»çˆ¬è™«è·å–æ•°æ®
            print("CSVæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œå°è¯•è·å–æ–°æ•°æ®...")
            spider = DLTSpider()
            lottery_data = spider.crawl_lottery_data(target_periods=100)
            if not lottery_data:
                print("æ— æ³•è·å–æ•°æ®ï¼Œç¨‹åºé€€å‡º")
                return

        # åˆ›å»ºåˆ†æå™¨å®ä¾‹
        analyzer = DLTAnalyzer(lottery_data)
        analyzer.save_data('å¤§ä¹é€å¼€å¥–æ•°æ®.csv')

        # ä¸»å¾ªç¯
        while True:
            show_menu()
            try:
                choice = input("è¯·è¾“å…¥é€‰æ‹©ï¼ˆ0-6ï¼‰ï¼š").strip()

                if choice == '0':
                    print("æ„Ÿè°¢ä½¿ç”¨å¤§ä¹é€æ•°æ®åˆ†æç³»ç»Ÿï¼")
                    break
                elif choice == '1':
                    print("\næ‰§è¡Œé”€å”®é¢è¶‹åŠ¿åˆ†æä¸é¢„æµ‹...")
                    analyzer.analyze_sales_trend()
                elif choice == '2':
                    print("\næ‰§è¡Œå·ç é¢‘ç‡ç»Ÿè®¡ä¸å¯è§†åŒ–åˆ†æ...")
                    analyzer.analyze_number_frequency(top_n=10)
                elif choice == '3':
                    print("\næ‰§è¡Œæ™ºèƒ½å·ç é¢„æµ‹...")
                    predicted_front, predicted_back = analyzer.predict_lottery_numbers()
                    if predicted_front and predicted_back:
                        front_str = [f"{num:02d}" for num in sorted(predicted_front)]
                        back_str = [f"{num:02d}" for num in sorted(predicted_back)]
                        print(f"\nğŸ¯ 2025å¹´7æœˆ1æ—¥åæœ€æ–°ä¸€æœŸæ¨èå·ç ï¼š")
                        print(f"å‰åŒºï¼š{' '.join(front_str)}")
                        print(f"ååŒºï¼š{' '.join(back_str)}")
                elif choice == '4':
                    print("\næ‰§è¡Œä¸åŒå¼€å¥–æ—¥å¯¹æ¯”åˆ†æ...")
                    analyzer.analyze_weekday_patterns()
                elif choice == '5':
                    print("=== ä¸“å®¶æ•°æ®åˆ†æåŠŸèƒ½ ===")

                    # åˆ›å»ºä¸“å®¶åˆ†æå™¨å®ä¾‹
                    analyzer1 = ExpertAnalyzer()
                    # è¿è¡Œå®Œæ•´çš„ä¸“å®¶æ•°æ®åˆ†ææµç¨‹
                    result_df = analyzer1.run_expert_analysis()
                    if result_df is not None:
                        print(f"æˆåŠŸåˆ†æäº† {len(result_df)} ä½ä¸“å®¶çš„æ•°æ®")
                    else:
                        print("\nâŒ ä¸“å®¶æ•°æ®åˆ†æåŠŸèƒ½æµ‹è¯•å¤±è´¥ï¼")

                elif choice == '6':
                    print("\nç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š...")
                    # æ‰§è¡Œæ‰€æœ‰åˆ†æ
                    analyzer.analyze_sales_trend()
                    analyzer.analyze_number_frequency(top_n=10)
                    predicted_front, predicted_back = analyzer.predict_lottery_numbers()
                    analyzer.analyze_weekday_patterns()
                    analyzer.analyze_expert_data()

                    if predicted_front and predicted_back:
                        front_str = [f"{num:02d}" for num in sorted(predicted_front)]
                        back_str = [f"{num:02d}" for num in sorted(predicted_back)]
                        print(f"\nğŸ¯ æœ€ç»ˆæ¨èå·ç ï¼š")
                        print(f"å‰åŒºï¼š{' '.join(front_str)}")
                        print(f"ååŒºï¼š{' '.join(back_str)}")
                else:
                    print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥ï¼")

                input("\næŒ‰å›è½¦é”®ç»§ç»­...")

            except KeyboardInterrupt:
                print("\n\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
                break
            except Exception as e:
                print(f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{e}")
                input("æŒ‰å›è½¦é”®ç»§ç»­...")

    except Exception as e:
        print(f"ç¨‹åºå¯åŠ¨å¤±è´¥ï¼š{e}")



class ExpertAnalyzer:
    def __init__(self):
        self.expert_list_url = "https://i.cmzj.net/expert/rankingList?limit=30&page=1&lottery=23&quota=1&type=2&target=%E6%80%BB%E5%88%86&classPay=2&issueNum=7"
        self.expert_detail_url = "https://www.cmzj.net/expertItem?id={}"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'zh-CN,zh;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Referer': 'https://www.cmzj.net/',
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)

    def get_expert_list(self):
        """è·å–ä¸“å®¶åˆ—è¡¨æ•°æ®"""
        try:
            print("æ­£åœ¨è·å–ä¸“å®¶åˆ—è¡¨...")
            response = self.session.get(self.expert_list_url, timeout=10)
            response.raise_for_status()

            data = response.json()
            if data.get('code') == 0 and 'data' in data:
                experts = data['data']
                print(f"æˆåŠŸè·å–åˆ° {len(experts)} ä½ä¸“å®¶çš„åŸºæœ¬ä¿¡æ¯")
                return experts
            else:
                print("APIè¿”å›æ•°æ®æ ¼å¼é”™è¯¯")
                return None

        except requests.RequestException as e:
            print(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
            # å¦‚æœç½‘ç»œè¯·æ±‚å¤±è´¥ï¼Œå°è¯•ä»æœ¬åœ°JSONæ–‡ä»¶è¯»å–
            try:
                print("å°è¯•ä»æœ¬åœ°JSONæ–‡ä»¶è¯»å–æ•°æ®...")
                with open('zj.json', 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if data.get('code') == 0 and 'data' in data:
                        experts = data['data']
                        print(f"ä»æœ¬åœ°æ–‡ä»¶æˆåŠŸè¯»å–åˆ° {len(experts)} ä½ä¸“å®¶çš„åŸºæœ¬ä¿¡æ¯")
                        return experts
            except FileNotFoundError:
                print("æœ¬åœ°JSONæ–‡ä»¶ä¸å­˜åœ¨")
            except json.JSONDecodeError:
                print("æœ¬åœ°JSONæ–‡ä»¶æ ¼å¼é”™è¯¯")
            return None

    def get_expert_detail(self, expert_id, expert_name):
        """è·å–ä¸“å®¶è¯¦ç»†ä¿¡æ¯"""
        try:
            url = self.expert_detail_url.format(expert_id)
            print(f"æ­£åœ¨è·å–ä¸“å®¶ {expert_name} (ID: {expert_id}) çš„è¯¦ç»†ä¿¡æ¯...")

            # é…ç½®æµè§ˆå™¨é€‰é¡¹
            options = webdriver.ChromeOptions()
            options.add_argument('--headless')  # æ— å¤´æ¨¡å¼
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')

            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=options)

            driver.get(url)
            time.sleep(2)

            # ç­‰å¾…é¡µé¢åŠ è½½
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CLASS_NAME, "okami-text"))
            )

            # è·å–é¡µé¢HTML
            html = driver.page_source
            driver.quit()

            return self.parse_expert_detail(html, expert_name)

        except Exception as e:
            print(f"è·å–ä¸“å®¶ {expert_name} è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}")
            return None

    def parse_expert_detail(self, html, expert_name):
        """è§£æä¸“å®¶è¯¦ç»†ä¿¡æ¯"""
        try:
            soup = BeautifulSoup(html, 'html.parser')

            # åˆå§‹åŒ–è¿”å›æ•°æ®
            detail_data = {
                'name': expert_name,
                'experience_years': 0,
                'article_count': 0,
                'total_awards': 0
            }

            # æŸ¥æ‰¾åŒ…å«ä¸“å®¶ä¿¡æ¯çš„div
            okami_text = soup.find('div', class_='okami-text')
            if not okami_text:
                print(f"æœªæ‰¾åˆ°ä¸“å®¶ {expert_name} çš„è¯¦ç»†ä¿¡æ¯åŒºåŸŸ")
                return detail_data

            # æå–å½©é¾„
            for p in okami_text.find_all('p'):
                text = p.get_text()
                if 'å½©é¾„ï¼š' in text:
                    years_match = re.search(r'å½©é¾„ï¼š\s*(\d+)å¹´', text)
                    if years_match:
                        detail_data['experience_years'] = int(years_match.group(1))
                        print(f"  å½©é¾„: {detail_data['experience_years']}å¹´")

                # æå–æ–‡ç« æ•°é‡
                elif 'æ–‡ç« æ•°é‡ï¼š' in text:
                    articles_match = re.search(r'æ–‡ç« æ•°é‡ï¼š\s*(\d+)ç¯‡', text)
                    if articles_match:
                        detail_data['article_count'] = int(articles_match.group(1))
                        print(f"  æ–‡ç« æ•°é‡: {detail_data['article_count']}ç¯‡")

            # æå–åŒè‰²çƒå¤§å¥–æˆ˜ç»©
            djzj_divs = soup.find_all('div', class_='djzj')
            for djzj in djzj_divs:
                span = djzj.find('span', class_='text-head-bg')
                if span and 'åŒè‰²çƒ' in span.get_text():
                    # ç»Ÿè®¡æ‰€æœ‰å¥–é¡¹
                    items = djzj.find_all('div', class_='item')
                    total_awards = 0
                    for item in items:
                        award_match = re.search(r'(\d+)æ¬¡', item.get_text())
                        if award_match:
                            total_awards += int(award_match.group(1))

                    detail_data['total_awards'] = total_awards
                    print(f"  åŒè‰²çƒæ€»è·å¥–æ¬¡æ•°: {total_awards}æ¬¡")
                    break

            return detail_data

        except Exception as e:
            print(f"è§£æä¸“å®¶ {expert_name} è¯¦ç»†ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            return {
                'name': expert_name,
                'experience_years': 0,
                'article_count': 0,
                'total_awards': 0
            }

    def crawl_experts_data(self):
        """çˆ¬å–æ‰€æœ‰ä¸“å®¶æ•°æ®"""
        # è·å–ä¸“å®¶åˆ—è¡¨
        experts_list = self.get_expert_list()
        if not experts_list:
            print("æ— æ³•è·å–ä¸“å®¶åˆ—è¡¨ï¼Œç¨‹åºé€€å‡º")
            return None

        all_expert_data = []

        # é™åˆ¶è·å–å‰30ä½ä¸“å®¶
        experts_to_process = experts_list[:30]

        for i, expert in enumerate(experts_to_process):
            expert_id = expert.get('expertId')
            expert_name = expert.get('name', f'ä¸“å®¶{i+1}')

            print(f"\nå¤„ç†ç¬¬ {i+1}/30 ä½ä¸“å®¶: {expert_name}")

            # è·å–åŸºæœ¬ä¿¡æ¯
            basic_data = {
                'expert_id': expert_id,
                'name': expert_name,
                'lottery': expert.get('lottery', 0),
                'follow': expert.get('follow', 0),
                'grade_name': expert.get('gradeName', ''),
                'rank': expert.get('rank', 0),
                'norm': expert.get('norm', 0),
                'best_record': expert.get('bestRecord', ''),
                'good_record': expert.get('goodRecord', '')
            }

            # è·å–è¯¦ç»†ä¿¡æ¯
            detail_data = self.get_expert_detail(expert_id, expert_name)
            if detail_data:
                # åˆå¹¶åŸºæœ¬ä¿¡æ¯å’Œè¯¦ç»†ä¿¡æ¯
                basic_data.update(detail_data)

            all_expert_data.append(basic_data)

            # æ·»åŠ å»¶æ—¶é¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(1)

        return all_expert_data

    def save_to_csv(self, expert_data, filename='expert_analysis_result.csv'):
        """ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶"""
        try:
            df = pd.DataFrame(expert_data)
            df.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f"\næ•°æ®å·²ä¿å­˜åˆ° {filename}")
            print(f"å…±ä¿å­˜äº† {len(df)} ä½ä¸“å®¶çš„æ•°æ®")
            return df
        except Exception as e:
            print(f"ä¿å­˜CSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return None

    def analyze_and_visualize(self, df):
        """åˆ†ææ•°æ®å¹¶è¿›è¡Œå¯è§†åŒ–"""
        if df is None or df.empty:
            print("æ²¡æœ‰æ•°æ®å¯ä¾›åˆ†æ")
            return

        print("\nå¼€å§‹æ•°æ®åˆ†æå’Œå¯è§†åŒ–...")

        # è®¾ç½®å›¾å½¢æ ·å¼
        fig = plt.figure(figsize=(20, 15))

        # 1. å½©é¾„åˆ†å¸ƒ
        plt.subplot(3, 4, 1)
        plt.hist(df['experience_years'], bins=10, alpha=0.7, color='skyblue', edgecolor='black')
        plt.title('ä¸“å®¶å½©é¾„åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        plt.xlabel('å½©é¾„ï¼ˆå¹´ï¼‰')
        plt.ylabel('äººæ•°')
        plt.grid(True, alpha=0.3)

        # 2. æ–‡ç« æ•°é‡åˆ†å¸ƒ
        plt.subplot(3, 4, 2)
        plt.hist(df['article_count'], bins=15, alpha=0.7, color='lightgreen', edgecolor='black')
        plt.title('ä¸“å®¶æ–‡ç« æ•°é‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        plt.xlabel('æ–‡ç« æ•°é‡')
        plt.ylabel('äººæ•°')
        plt.grid(True, alpha=0.3)

        # 3. è·å¥–æ¬¡æ•°åˆ†å¸ƒ
        plt.subplot(3, 4, 3)
        plt.hist(df['total_awards'], bins=10, alpha=0.7, color='lightcoral', edgecolor='black')
        plt.title('ä¸“å®¶è·å¥–æ¬¡æ•°åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        plt.xlabel('è·å¥–æ¬¡æ•°')
        plt.ylabel('äººæ•°')
        plt.grid(True, alpha=0.3)

        # 4. ä¸“å®¶ç­‰çº§åˆ†å¸ƒ
        plt.subplot(3, 4, 4)
        grade_counts = df['grade_name'].value_counts()
        plt.pie(grade_counts.values, labels=grade_counts.index, autopct='%1.1f%%', startangle=90)
        plt.title('ä¸“å®¶ç­‰çº§åˆ†å¸ƒ', fontsize=14, fontweight='bold')

        # 5. å½©é¾„ä¸æ–‡ç« æ•°é‡çš„å…³ç³»
        plt.subplot(3, 4, 5)
        plt.scatter(df['experience_years'], df['article_count'], alpha=0.6, color='purple')
        plt.title('å½©é¾„ä¸æ–‡ç« æ•°é‡å…³ç³»', fontsize=14, fontweight='bold')
        plt.xlabel('å½©é¾„ï¼ˆå¹´ï¼‰')
        plt.ylabel('æ–‡ç« æ•°é‡')
        plt.grid(True, alpha=0.3)

        # è®¡ç®—ç›¸å…³ç³»æ•°
        corr_exp_article = df['experience_years'].corr(df['article_count'])
        plt.text(0.05, 0.95, f'ç›¸å…³ç³»æ•°: {corr_exp_article:.3f}',
                transform=plt.gca().transAxes, fontsize=10,
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

        # 6. å½©é¾„ä¸è·å¥–æ¬¡æ•°çš„å…³ç³»
        plt.subplot(3, 4, 6)
        plt.scatter(df['experience_years'], df['total_awards'], alpha=0.6, color='orange')
        plt.title('å½©é¾„ä¸è·å¥–æ¬¡æ•°å…³ç³»', fontsize=14, fontweight='bold')
        plt.xlabel('å½©é¾„ï¼ˆå¹´ï¼‰')
        plt.ylabel('è·å¥–æ¬¡æ•°')
        plt.grid(True, alpha=0.3)

        # è®¡ç®—ç›¸å…³ç³»æ•°
        corr_exp_awards = df['experience_years'].corr(df['total_awards'])
        plt.text(0.05, 0.95, f'ç›¸å…³ç³»æ•°: {corr_exp_awards:.3f}',
                transform=plt.gca().transAxes, fontsize=10,
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

        # 7. æ–‡ç« æ•°é‡ä¸è·å¥–æ¬¡æ•°çš„å…³ç³»
        plt.subplot(3, 4, 7)
        plt.scatter(df['article_count'], df['total_awards'], alpha=0.6, color='brown')
        plt.title('æ–‡ç« æ•°é‡ä¸è·å¥–æ¬¡æ•°å…³ç³»', fontsize=14, fontweight='bold')
        plt.xlabel('æ–‡ç« æ•°é‡')
        plt.ylabel('è·å¥–æ¬¡æ•°')
        plt.grid(True, alpha=0.3)

        # è®¡ç®—ç›¸å…³ç³»æ•°
        corr_article_awards = df['article_count'].corr(df['total_awards'])
        plt.text(0.05, 0.95, f'ç›¸å…³ç³»æ•°: {corr_article_awards:.3f}',
                transform=plt.gca().transAxes, fontsize=10,
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

        # 8. ä¸åŒç­‰çº§ä¸“å®¶çš„è·å¥–æƒ…å†µ
        plt.subplot(3, 4, 8)
        grade_awards = df.groupby('grade_name')['total_awards'].mean().sort_values(ascending=False)
        grade_awards.plot(kind='bar', color='teal', alpha=0.7)
        plt.title('ä¸åŒç­‰çº§ä¸“å®¶å¹³å‡è·å¥–æ¬¡æ•°', fontsize=14, fontweight='bold')
        plt.xlabel('ä¸“å®¶ç­‰çº§')
        plt.ylabel('å¹³å‡è·å¥–æ¬¡æ•°')
        plt.xticks(rotation=45)
        plt.grid(True, alpha=0.3)

        # 9. å…³æ³¨åº¦åˆ†å¸ƒ
        plt.subplot(3, 4, 9)
        plt.hist(df['follow'], bins=10, alpha=0.7, color='gold', edgecolor='black')
        plt.title('ä¸“å®¶å…³æ³¨åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        plt.xlabel('å…³æ³¨äººæ•°')
        plt.ylabel('ä¸“å®¶äººæ•°')
        plt.grid(True, alpha=0.3)

        # 10. ç§¯åˆ†åˆ†å¸ƒ
        plt.subplot(3, 4, 10)
        plt.hist(df['norm'], bins=15, alpha=0.7, color='pink', edgecolor='black')
        plt.title('ä¸“å®¶ç§¯åˆ†åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        plt.xlabel('ç§¯åˆ†')
        plt.ylabel('ä¸“å®¶äººæ•°')
        plt.grid(True, alpha=0.3)

        # 11. ä¸­å¥–ç‡åˆ†æï¼ˆè·å¥–æ¬¡æ•°/æ–‡ç« æ•°é‡ï¼‰
        plt.subplot(3, 4, 11)
        # é¿å…é™¤é›¶é”™è¯¯
        df['win_rate'] = df.apply(lambda x: x['total_awards'] / x['article_count'] if x['article_count'] > 0 else 0, axis=1)
        plt.hist(df['win_rate'], bins=10, alpha=0.7, color='cyan', edgecolor='black')
        plt.title('ä¸“å®¶ä¸­å¥–ç‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        plt.xlabel('ä¸­å¥–ç‡ï¼ˆè·å¥–æ¬¡æ•°/æ–‡ç« æ•°é‡ï¼‰')
        plt.ylabel('ä¸“å®¶äººæ•°')
        plt.grid(True, alpha=0.3)

        # 12. ç»¼åˆåˆ†æçƒ­åŠ›å›¾
        plt.subplot(3, 4, 12)
        correlation_data = df[['experience_years', 'article_count', 'total_awards', 'follow', 'norm', 'win_rate']].corr()
        sns.heatmap(correlation_data, annot=True, cmap='coolwarm', center=0,
                   square=True, linewidths=0.5, cbar_kws={"shrink": .8})
        plt.title('å„æŒ‡æ ‡ç›¸å…³æ€§çƒ­åŠ›å›¾', fontsize=14, fontweight='bold')

        plt.tight_layout()
        plt.savefig('expert_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()

        # è¾“å‡ºç»Ÿè®¡æ‘˜è¦
        print("\n=== ä¸“å®¶æ•°æ®ç»Ÿè®¡æ‘˜è¦ ===")
        print(f"æ€»ä¸“å®¶æ•°: {len(df)}")
        print(f"å¹³å‡å½©é¾„: {df['experience_years'].mean():.1f}å¹´")
        print(f"å¹³å‡æ–‡ç« æ•°: {df['article_count'].mean():.0f}ç¯‡")
        print(f"å¹³å‡è·å¥–æ¬¡æ•°: {df['total_awards'].mean():.1f}æ¬¡")
        print(f"å¹³å‡ä¸­å¥–ç‡: {df['win_rate'].mean():.3f}")
        print(f"å½©é¾„ä¸è·å¥–æ¬¡æ•°ç›¸å…³ç³»æ•°: {corr_exp_awards:.3f}")
        print(f"æ–‡ç« æ•°é‡ä¸è·å¥–æ¬¡æ•°ç›¸å…³ç³»æ•°: {corr_article_awards:.3f}")

        return df

    def run_expert_analysis(self):
        """è¿è¡Œä¸“å®¶æ•°æ®åˆ†æçš„å®Œæ•´æµç¨‹"""
        print("=== å¼€å§‹ä¸“å®¶æ•°æ®åˆ†æ ===")

        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦å­˜åœ¨å·²ä¿å­˜çš„ä¸“å®¶æ•°æ®æ–‡ä»¶
        expert_csv_file = 'expert_analysis_result.csv'
        expert_data = None
        df = None
        # å°è¯•ä»CSVæ–‡ä»¶è¯»å–ä¸“å®¶æ•°æ®
        print("æ­£åœ¨æ£€æŸ¥æœ¬åœ°ä¸“å®¶æ•°æ®æ–‡ä»¶...")
        df = pd.read_csv(expert_csv_file, encoding='utf-8-sig')

        if not df.empty and len(df) > 0:
            print(f"âœ… ä»æœ¬åœ°æ–‡ä»¶ `{expert_csv_file}` æˆåŠŸè¯»å–åˆ° {len(df)} ä½ä¸“å®¶çš„æ•°æ®")
            self.analyze_and_visualize(df)
        else:
            # 1. çˆ¬å–ä¸“å®¶æ•°æ®
            expert_data = self.crawl_experts_data()
            if not expert_data:
                print("æ•°æ®çˆ¬å–å¤±è´¥ï¼Œç¨‹åºç»“æŸ")
                return
            # 2. ä¿å­˜åˆ°CSV
            df = self.save_to_csv(expert_data)
            if df is None:
                print("æ•°æ®ä¿å­˜å¤±è´¥ï¼Œç¨‹åºç»“æŸ")
                return
            # 3. æ•°æ®åˆ†æå’Œå¯è§†åŒ–
            self.analyze_and_visualize(df)

        print("\n=== ä¸“å®¶æ•°æ®åˆ†æå®Œæˆ ===")
        return df

if __name__ == "__main__":
    main()